{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ef5c053",
      "metadata": {
        "papermill": {
          "duration": 0.002848,
          "end_time": "2026-01-06T03:35:21.884834",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.881986",
          "status": "completed"
        },
        "tags": [],
        "id": "3ef5c053"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Ic6JDbHAIXph"
      },
      "id": "Ic6JDbHAIXph",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f46f8cc",
      "metadata": {
        "papermill": {
          "duration": 0.00149,
          "end_time": "2026-01-06T03:35:21.887999",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.886509",
          "status": "completed"
        },
        "tags": [],
        "id": "4f46f8cc"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c2fc92c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.892327Z",
          "iopub.status.busy": "2026-01-06T03:35:21.891944Z",
          "iopub.status.idle": "2026-01-06T03:35:21.898008Z",
          "shell.execute_reply": "2026-01-06T03:35:21.897511Z"
        },
        "papermill": {
          "duration": 0.009684,
          "end_time": "2026-01-06T03:35:21.899305",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.889621",
          "status": "completed"
        },
        "tags": [],
        "id": "8c2fc92c"
      },
      "outputs": [],
      "source": [
        "WORKING_DIR = \"/kaggle/working/\"\n",
        "CODE_DIR = \"/kaggle/temp/src\"\n",
        "GDRIVE_DIR = \"/content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshm5WvXIdZB",
        "outputId": "308c8c26-471d-4f8d-9a5b-3d586591cb6f"
      },
      "id": "Jshm5WvXIdZB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061a8517",
      "metadata": {
        "papermill": {
          "duration": 0.001467,
          "end_time": "2026-01-06T03:35:21.902523",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.901056",
          "status": "completed"
        },
        "tags": [],
        "id": "061a8517"
      },
      "source": [
        "## Download code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! Change branch name if not main\n",
        "BRANCH = \"main\""
      ],
      "metadata": {
        "id": "FFXhOBNLIv0Q"
      },
      "id": "FFXhOBNLIv0Q",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6deb560c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.906915Z",
          "iopub.status.busy": "2026-01-06T03:35:21.906454Z",
          "iopub.status.idle": "2026-01-06T03:35:22.809240Z",
          "shell.execute_reply": "2026-01-06T03:35:22.808363Z"
        },
        "papermill": {
          "duration": 0.906975,
          "end_time": "2026-01-06T03:35:22.811057",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.904082",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6deb560c",
        "outputId": "a5963bca-f319-4877-cc91-db6197b29a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/temp/src\n"
          ]
        }
      ],
      "source": [
        "# If directory \"src\" not exist then clone a new one\n",
        "!pwd\n",
        "![ -d \"{CODE_DIR}\" ] || git clone --depth 1  --branch \"{BRANCH}\" \"https://github.com/aio25-mix002/m07-p7.1\" \"{CODE_DIR}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1fdc6b4",
      "metadata": {
        "papermill": {
          "duration": 0.002046,
          "end_time": "2026-01-06T03:35:22.814997",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.812951",
          "status": "completed"
        },
        "tags": [],
        "id": "a1fdc6b4"
      },
      "source": [
        "## Fetch the latest code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "29c3a280",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:22.819938Z",
          "iopub.status.busy": "2026-01-06T03:35:22.819676Z",
          "iopub.status.idle": "2026-01-06T03:35:23.462681Z",
          "shell.execute_reply": "2026-01-06T03:35:23.461828Z"
        },
        "papermill": {
          "duration": 0.647535,
          "end_time": "2026-01-06T03:35:23.464347",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.816812",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29c3a280",
        "outputId": "1e6ebe3e-b650-4f6b-cba2-27100bde54e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/temp/src\n",
            "Removing src/__pycache__/\n",
            "On branch ngocdung/make-inference-n-submit\n",
            "Your branch is up to date with 'origin/ngocdung/make-inference-n-submit'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Already up to date.\n",
            "/kaggle/temp/src\n"
          ]
        }
      ],
      "source": [
        "# Go to CODE_DIR, Fetch the latest code\n",
        "%cd {CODE_DIR}\n",
        "!git clean -fdx\n",
        "!git status\n",
        "!git pull\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "g4QEb2HlZMiD"
      },
      "id": "g4QEb2HlZMiD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6315fe81"
      },
      "source": [
        "### Option 1: Using Kaggle API Credentials (Only if data in Google Drive not available)\n",
        "\n",
        "First, ensure you have downloaded your `kaggle.json` API token from your Kaggle account. Once downloaded, upload it to your Colab session. You can do this via the 'Files' tab on the left sidebar.\n",
        "\n",
        "After uploading, we will move it to the correct directory (`~/.kaggle/`) and set the necessary permissions."
      ],
      "id": "6315fe81"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "645da322",
        "outputId": "637ca82d-dbb2-440b-9c56-2c5ba5e38824"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create the .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move the uploaded kaggle.json file to the .kaggle directory\n",
        "# Assuming kaggle.json is in the current working directory after upload\n",
        "# If you uploaded it to a different path, please adjust '/content/kaggle.json'\n",
        "!mv /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print('Kaggle API credentials set up successfully!')\n",
        "!ls -la ~/.kaggle/kaggle.json"
      ],
      "id": "645da322",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API credentials set up successfully!\n",
            "-rw------- 1 root root 67 Jan  9 07:52 /root/.kaggle/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python download_data.py\n",
        "!kaggle competitions download -c action-video\n",
        "!unzip -q action-video.zip  -d {WORKING_DIR}"
      ],
      "metadata": {
        "id": "l6odimieZMIC",
        "outputId": "b55e487a-7db3-4e14-a35e-421c85b00a65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading action-video.zip to /kaggle/temp/src\n",
            " 97% 3.06G/3.14G [00:10<00:00, 161MB/s] \n",
            "100% 3.14G/3.14G [00:10<00:00, 316MB/s]\n"
          ]
        }
      ],
      "id": "l6odimieZMIC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Unused due to synchronizing problem) Option 2: Using data saved in Google Drive\n"
      ],
      "metadata": {
        "id": "lmes98ROmYtp"
      },
      "id": "lmes98ROmYtp"
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# source_gdrive_data_path = os.path.join(GDRIVE_DIR, 'Data')\n",
        "# destination_working_data_path = os.path.join(WORKING_DIR, 'data')\n",
        "\n",
        "# print(f\"Attempting to copy data from Google Drive: {source_gdrive_data_path}\")\n",
        "# print(f\"To working directory: {destination_working_data_path}\")\n",
        "\n",
        "# try:\n",
        "#     # Create the destination directory if it doesn't exist. If it exists, remove it first to avoid errors.\n",
        "#     if os.path.exists(destination_working_data_path):\n",
        "#         print(f\"Destination directory {destination_working_data_path} already exists. Removing before copy...\")\n",
        "#         shutil.rmtree(destination_working_data_path)\n",
        "\n",
        "#     shutil.copytree(source_gdrive_data_path, destination_working_data_path)\n",
        "#     print(f\"Successfully copied '{source_gdrive_data_path}' to '{destination_working_data_path}'\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: Source data directory not found in Google Drive at {source_gdrive_data_path}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred while copying the data from Google Drive: {e}\")"
      ],
      "metadata": {
        "id": "duTIwNE6mYJ-"
      },
      "id": "duTIwNE6mYJ-",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9a407c42",
      "metadata": {
        "papermill": {
          "duration": 0.001813,
          "end_time": "2026-01-06T03:35:23.468110",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.466297",
          "status": "completed"
        },
        "tags": [],
        "id": "9a407c42"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "CeiM2_IIk9wX"
      },
      "id": "CeiM2_IIk9wX"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "papermill": {
          "duration": 0.001816,
          "end_time": "2026-01-06T03:35:23.471692",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.469876",
          "status": "completed"
        },
        "tags": [],
        "outputId": "6df7bce2-fd40-4e40-997e-bd518e87cc6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tt-BYnxIpHa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Initializing datasets...\n",
            "Train size: 5628 | Val size: 626\n",
            "Creating model...\n",
            "Downloading vit_base_patch16_224 weights via timm...\n",
            "model.safetensors: 100% 346M/346M [00:00<00:00, 360MB/s]\n",
            "Loaded pretrained weights. Missing: 132, Unexpected: 0\n",
            "ðŸš€ Compiling model with torch.compile...\n",
            "\n",
            "============================================================\n",
            "Training Configuration:\n",
            "  Epochs: 1\n",
            "  Batch size: 8\n",
            "  Learning rate: 0.0001\n",
            "  Num frames: 16\n",
            "  Frame stride: 2\n",
            "  Val ratio: 0.1\n",
            "  Checkpoint dir: ./checkpoints\n",
            "============================================================\n",
            "\n",
            "Backbone FROZEN (Chá»‰ train SMIF & Head)\n",
            "\n",
            "Epoch 1/1\n",
            "Train:   0% 0/704 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n",
            "W0109 08:04:42.137000 7886 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "Train Loss: 3.4038 | Acc: 0.1629\n",
            "Val Loss: 3.3379   | Acc: 0.2093\n",
            "New best model saved! (0.2093)\n",
            "\n",
            "Training complete! Best validation accuracy: 0.2093\n"
          ]
        }
      ],
      "source": [
        "# Training - can change number of epochs\n",
        "!python train.py #--epochs 1"
      ],
      "id": "6tt-BYnxIpHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the best checkpoint to Google Drive"
      ],
      "metadata": {
        "id": "Ur0NsX_WhB8s"
      },
      "id": "Ur0NsX_WhB8s"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the brief note for the filename\n",
        "NOTE = \"vanilla\" # !!! Should edit every new run\n",
        "SAVE_PATH = f\"{GDRIVE_DIR}Artifacts/Checkpoints\"\n"
      ],
      "metadata": {
        "id": "u_Bun8y2hPnQ"
      },
      "execution_count": 29,
      "outputs": [],
      "id": "u_Bun8y2hPnQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the source path of the best model checkpoint\n",
        "source_checkpoint_path = os.path.join(CODE_DIR, 'checkpoints', 'best_model.pth')\n",
        "\n",
        "# Define your Google Drive destination folder path\n",
        "# IMPORTANT: Please replace 'YOUR_GOOGLE_DRIVE_FOLDER_PATH' with the actual path to your folder in Google Drive.\n",
        "# For example, it might be '/content/drive/MyDrive/MyProjectCheckpoints/'\n",
        "\n",
        "# Ensure the Google Drive folder exists\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)\n",
        "    print(f\"Created Google Drive folder: {SAVE_PATH}\")\n",
        "\n",
        "# Generate a timestamp for the filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the new filename for the checkpoint\n",
        "new_checkpoint_filename = f\"model_{timestamp}_{NOTE}.pth\"\n",
        "destination_checkpoint_path = os.path.join(SAVE_PATH, new_checkpoint_filename)\n",
        "\n",
        "# Copy the checkpoint\n",
        "try:\n",
        "    shutil.copy(source_checkpoint_path, destination_checkpoint_path)\n",
        "    print(f\"Checkpoint successfully saved to: {destination_checkpoint_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Source checkpoint not found at {source_checkpoint_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the checkpoint: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mhJA7Kf7VB",
        "outputId": "06f6eddf-3710-4d96-954d-e27b36cc0e25"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint successfully saved to: /content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/Artifacts/Checkpoints/model_20260109_082113_vanilla.pth\n"
          ]
        }
      ],
      "id": "p-mhJA7Kf7VB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reload the checkpoint (if needed)"
      ],
      "metadata": {
        "id": "fRJzvxFzhumr"
      },
      "id": "fRJzvxFzhumr"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# # Define the path to the checkpoint file\n",
        "destination_checkpoint_path = source_checkpoint_path #f'{GDRIVE_DIR}Artifacts/Checkpoints/model_20260107_081244_vanilla.pth'\n",
        "\n",
        "# Check if the checkpoint file exists\n",
        "if os.path.exists(destination_checkpoint_path):\n",
        "    # Load the checkpoint\n",
        "    loaded_checkpoint = torch.load(destination_checkpoint_path, map_location=torch.device('cpu')) # Use 'cuda' if you want to load to GPU\n",
        "    print(f\"Checkpoint loaded successfully from: {destination_checkpoint_path}\")\n",
        "    print(\"Keys in the loaded checkpoint:\", loaded_checkpoint.keys())\n",
        "\n",
        "    # Example of how you might load it into a model (assuming 'model' is defined)\n",
        "    # model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
        "    # epoch = loaded_checkpoint['epoch']\n",
        "    # loss = loaded_checkpoint['loss']\n",
        "else:\n",
        "    print(f\"Error: Checkpoint not found at {destination_checkpoint_path}\")\n"
      ],
      "metadata": {
        "id": "l3UZYdnshyZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b725fd-1923-4e63-a838-13f81cfff787"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded successfully from: /kaggle/temp/src/checkpoints/best_model.pth\n",
            "Keys in the loaded checkpoint: odict_keys(['_orig_mod.smif.alpha', '_orig_mod.smif.conv_fuse.weight', '_orig_mod.smif.conv_fuse.bias', '_orig_mod.backbone.cls_token', '_orig_mod.backbone.pos_embed', '_orig_mod.backbone.patch_embed.proj.weight', '_orig_mod.backbone.patch_embed.proj.bias', '_orig_mod.backbone.blocks.0.norm1.weight', '_orig_mod.backbone.blocks.0.norm1.bias', '_orig_mod.backbone.blocks.0.attn.qkv.weight', '_orig_mod.backbone.blocks.0.attn.qkv.bias', '_orig_mod.backbone.blocks.0.attn.proj.weight', '_orig_mod.backbone.blocks.0.attn.proj.bias', '_orig_mod.backbone.blocks.0.norm2.weight', '_orig_mod.backbone.blocks.0.norm2.bias', '_orig_mod.backbone.blocks.0.mlp.fc1.weight', '_orig_mod.backbone.blocks.0.mlp.fc1.bias', '_orig_mod.backbone.blocks.0.mlp.fc2.weight', '_orig_mod.backbone.blocks.0.mlp.fc2.bias', '_orig_mod.backbone.blocks.0.lmim.delta', '_orig_mod.backbone.blocks.0.lmim.reduce.weight', '_orig_mod.backbone.blocks.0.lmim.reduce.bias', '_orig_mod.backbone.blocks.0.lmim.expand.weight', '_orig_mod.backbone.blocks.0.lmim.expand.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.1.norm1.weight', '_orig_mod.backbone.blocks.1.norm1.bias', '_orig_mod.backbone.blocks.1.attn.qkv.weight', '_orig_mod.backbone.blocks.1.attn.qkv.bias', '_orig_mod.backbone.blocks.1.attn.proj.weight', '_orig_mod.backbone.blocks.1.attn.proj.bias', '_orig_mod.backbone.blocks.1.norm2.weight', '_orig_mod.backbone.blocks.1.norm2.bias', '_orig_mod.backbone.blocks.1.mlp.fc1.weight', '_orig_mod.backbone.blocks.1.mlp.fc1.bias', '_orig_mod.backbone.blocks.1.mlp.fc2.weight', '_orig_mod.backbone.blocks.1.mlp.fc2.bias', '_orig_mod.backbone.blocks.1.lmim.delta', '_orig_mod.backbone.blocks.1.lmim.reduce.weight', '_orig_mod.backbone.blocks.1.lmim.reduce.bias', '_orig_mod.backbone.blocks.1.lmim.expand.weight', '_orig_mod.backbone.blocks.1.lmim.expand.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.2.norm1.weight', '_orig_mod.backbone.blocks.2.norm1.bias', '_orig_mod.backbone.blocks.2.attn.qkv.weight', '_orig_mod.backbone.blocks.2.attn.qkv.bias', '_orig_mod.backbone.blocks.2.attn.proj.weight', '_orig_mod.backbone.blocks.2.attn.proj.bias', '_orig_mod.backbone.blocks.2.norm2.weight', '_orig_mod.backbone.blocks.2.norm2.bias', '_orig_mod.backbone.blocks.2.mlp.fc1.weight', '_orig_mod.backbone.blocks.2.mlp.fc1.bias', '_orig_mod.backbone.blocks.2.mlp.fc2.weight', '_orig_mod.backbone.blocks.2.mlp.fc2.bias', '_orig_mod.backbone.blocks.2.lmim.delta', '_orig_mod.backbone.blocks.2.lmim.reduce.weight', '_orig_mod.backbone.blocks.2.lmim.reduce.bias', '_orig_mod.backbone.blocks.2.lmim.expand.weight', '_orig_mod.backbone.blocks.2.lmim.expand.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.3.norm1.weight', '_orig_mod.backbone.blocks.3.norm1.bias', '_orig_mod.backbone.blocks.3.attn.qkv.weight', '_orig_mod.backbone.blocks.3.attn.qkv.bias', '_orig_mod.backbone.blocks.3.attn.proj.weight', '_orig_mod.backbone.blocks.3.attn.proj.bias', '_orig_mod.backbone.blocks.3.norm2.weight', '_orig_mod.backbone.blocks.3.norm2.bias', '_orig_mod.backbone.blocks.3.mlp.fc1.weight', '_orig_mod.backbone.blocks.3.mlp.fc1.bias', '_orig_mod.backbone.blocks.3.mlp.fc2.weight', '_orig_mod.backbone.blocks.3.mlp.fc2.bias', '_orig_mod.backbone.blocks.3.lmim.delta', '_orig_mod.backbone.blocks.3.lmim.reduce.weight', '_orig_mod.backbone.blocks.3.lmim.reduce.bias', '_orig_mod.backbone.blocks.3.lmim.expand.weight', '_orig_mod.backbone.blocks.3.lmim.expand.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.4.norm1.weight', '_orig_mod.backbone.blocks.4.norm1.bias', '_orig_mod.backbone.blocks.4.attn.qkv.weight', '_orig_mod.backbone.blocks.4.attn.qkv.bias', '_orig_mod.backbone.blocks.4.attn.proj.weight', '_orig_mod.backbone.blocks.4.attn.proj.bias', '_orig_mod.backbone.blocks.4.norm2.weight', '_orig_mod.backbone.blocks.4.norm2.bias', '_orig_mod.backbone.blocks.4.mlp.fc1.weight', '_orig_mod.backbone.blocks.4.mlp.fc1.bias', '_orig_mod.backbone.blocks.4.mlp.fc2.weight', '_orig_mod.backbone.blocks.4.mlp.fc2.bias', '_orig_mod.backbone.blocks.4.lmim.delta', '_orig_mod.backbone.blocks.4.lmim.reduce.weight', '_orig_mod.backbone.blocks.4.lmim.reduce.bias', '_orig_mod.backbone.blocks.4.lmim.expand.weight', '_orig_mod.backbone.blocks.4.lmim.expand.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.5.norm1.weight', '_orig_mod.backbone.blocks.5.norm1.bias', '_orig_mod.backbone.blocks.5.attn.qkv.weight', '_orig_mod.backbone.blocks.5.attn.qkv.bias', '_orig_mod.backbone.blocks.5.attn.proj.weight', '_orig_mod.backbone.blocks.5.attn.proj.bias', '_orig_mod.backbone.blocks.5.norm2.weight', '_orig_mod.backbone.blocks.5.norm2.bias', '_orig_mod.backbone.blocks.5.mlp.fc1.weight', '_orig_mod.backbone.blocks.5.mlp.fc1.bias', '_orig_mod.backbone.blocks.5.mlp.fc2.weight', '_orig_mod.backbone.blocks.5.mlp.fc2.bias', '_orig_mod.backbone.blocks.5.lmim.delta', '_orig_mod.backbone.blocks.5.lmim.reduce.weight', '_orig_mod.backbone.blocks.5.lmim.reduce.bias', '_orig_mod.backbone.blocks.5.lmim.expand.weight', '_orig_mod.backbone.blocks.5.lmim.expand.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.6.norm1.weight', '_orig_mod.backbone.blocks.6.norm1.bias', '_orig_mod.backbone.blocks.6.attn.qkv.weight', '_orig_mod.backbone.blocks.6.attn.qkv.bias', '_orig_mod.backbone.blocks.6.attn.proj.weight', '_orig_mod.backbone.blocks.6.attn.proj.bias', '_orig_mod.backbone.blocks.6.norm2.weight', '_orig_mod.backbone.blocks.6.norm2.bias', '_orig_mod.backbone.blocks.6.mlp.fc1.weight', '_orig_mod.backbone.blocks.6.mlp.fc1.bias', '_orig_mod.backbone.blocks.6.mlp.fc2.weight', '_orig_mod.backbone.blocks.6.mlp.fc2.bias', '_orig_mod.backbone.blocks.6.lmim.delta', '_orig_mod.backbone.blocks.6.lmim.reduce.weight', '_orig_mod.backbone.blocks.6.lmim.reduce.bias', '_orig_mod.backbone.blocks.6.lmim.expand.weight', '_orig_mod.backbone.blocks.6.lmim.expand.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.7.norm1.weight', '_orig_mod.backbone.blocks.7.norm1.bias', '_orig_mod.backbone.blocks.7.attn.qkv.weight', '_orig_mod.backbone.blocks.7.attn.qkv.bias', '_orig_mod.backbone.blocks.7.attn.proj.weight', '_orig_mod.backbone.blocks.7.attn.proj.bias', '_orig_mod.backbone.blocks.7.norm2.weight', '_orig_mod.backbone.blocks.7.norm2.bias', '_orig_mod.backbone.blocks.7.mlp.fc1.weight', '_orig_mod.backbone.blocks.7.mlp.fc1.bias', '_orig_mod.backbone.blocks.7.mlp.fc2.weight', '_orig_mod.backbone.blocks.7.mlp.fc2.bias', '_orig_mod.backbone.blocks.7.lmim.delta', '_orig_mod.backbone.blocks.7.lmim.reduce.weight', '_orig_mod.backbone.blocks.7.lmim.reduce.bias', '_orig_mod.backbone.blocks.7.lmim.expand.weight', '_orig_mod.backbone.blocks.7.lmim.expand.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.8.norm1.weight', '_orig_mod.backbone.blocks.8.norm1.bias', '_orig_mod.backbone.blocks.8.attn.qkv.weight', '_orig_mod.backbone.blocks.8.attn.qkv.bias', '_orig_mod.backbone.blocks.8.attn.proj.weight', '_orig_mod.backbone.blocks.8.attn.proj.bias', '_orig_mod.backbone.blocks.8.norm2.weight', '_orig_mod.backbone.blocks.8.norm2.bias', '_orig_mod.backbone.blocks.8.mlp.fc1.weight', '_orig_mod.backbone.blocks.8.mlp.fc1.bias', '_orig_mod.backbone.blocks.8.mlp.fc2.weight', '_orig_mod.backbone.blocks.8.mlp.fc2.bias', '_orig_mod.backbone.blocks.8.lmim.delta', '_orig_mod.backbone.blocks.8.lmim.reduce.weight', '_orig_mod.backbone.blocks.8.lmim.reduce.bias', '_orig_mod.backbone.blocks.8.lmim.expand.weight', '_orig_mod.backbone.blocks.8.lmim.expand.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.9.norm1.weight', '_orig_mod.backbone.blocks.9.norm1.bias', '_orig_mod.backbone.blocks.9.attn.qkv.weight', '_orig_mod.backbone.blocks.9.attn.qkv.bias', '_orig_mod.backbone.blocks.9.attn.proj.weight', '_orig_mod.backbone.blocks.9.attn.proj.bias', '_orig_mod.backbone.blocks.9.norm2.weight', '_orig_mod.backbone.blocks.9.norm2.bias', '_orig_mod.backbone.blocks.9.mlp.fc1.weight', '_orig_mod.backbone.blocks.9.mlp.fc1.bias', '_orig_mod.backbone.blocks.9.mlp.fc2.weight', '_orig_mod.backbone.blocks.9.mlp.fc2.bias', '_orig_mod.backbone.blocks.9.lmim.delta', '_orig_mod.backbone.blocks.9.lmim.reduce.weight', '_orig_mod.backbone.blocks.9.lmim.reduce.bias', '_orig_mod.backbone.blocks.9.lmim.expand.weight', '_orig_mod.backbone.blocks.9.lmim.expand.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.10.norm1.weight', '_orig_mod.backbone.blocks.10.norm1.bias', '_orig_mod.backbone.blocks.10.attn.qkv.weight', '_orig_mod.backbone.blocks.10.attn.qkv.bias', '_orig_mod.backbone.blocks.10.attn.proj.weight', '_orig_mod.backbone.blocks.10.attn.proj.bias', '_orig_mod.backbone.blocks.10.norm2.weight', '_orig_mod.backbone.blocks.10.norm2.bias', '_orig_mod.backbone.blocks.10.mlp.fc1.weight', '_orig_mod.backbone.blocks.10.mlp.fc1.bias', '_orig_mod.backbone.blocks.10.mlp.fc2.weight', '_orig_mod.backbone.blocks.10.mlp.fc2.bias', '_orig_mod.backbone.blocks.10.lmim.delta', '_orig_mod.backbone.blocks.10.lmim.reduce.weight', '_orig_mod.backbone.blocks.10.lmim.reduce.bias', '_orig_mod.backbone.blocks.10.lmim.expand.weight', '_orig_mod.backbone.blocks.10.lmim.expand.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.11.norm1.weight', '_orig_mod.backbone.blocks.11.norm1.bias', '_orig_mod.backbone.blocks.11.attn.qkv.weight', '_orig_mod.backbone.blocks.11.attn.qkv.bias', '_orig_mod.backbone.blocks.11.attn.proj.weight', '_orig_mod.backbone.blocks.11.attn.proj.bias', '_orig_mod.backbone.blocks.11.norm2.weight', '_orig_mod.backbone.blocks.11.norm2.bias', '_orig_mod.backbone.blocks.11.mlp.fc1.weight', '_orig_mod.backbone.blocks.11.mlp.fc1.bias', '_orig_mod.backbone.blocks.11.mlp.fc2.weight', '_orig_mod.backbone.blocks.11.mlp.fc2.bias', '_orig_mod.backbone.blocks.11.lmim.delta', '_orig_mod.backbone.blocks.11.lmim.reduce.weight', '_orig_mod.backbone.blocks.11.lmim.reduce.bias', '_orig_mod.backbone.blocks.11.lmim.expand.weight', '_orig_mod.backbone.blocks.11.lmim.expand.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.norm.weight', '_orig_mod.backbone.norm.bias', '_orig_mod.head.weight', '_orig_mod.head.bias'])\n"
          ]
        }
      ],
      "id": "l3UZYdnshyZf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.001777,
          "end_time": "2026-01-06T03:35:23.475387",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.473610",
          "status": "completed"
        },
        "tags": [],
        "id": "mtDjbSeWIpHc"
      },
      "source": [
        "# Submission"
      ],
      "id": "mtDjbSeWIpHc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make submission file"
      ],
      "metadata": {
        "id": "sblI1-oItK2J"
      },
      "id": "sblI1-oItK2J"
    },
    {
      "cell_type": "code",
      "source": [
        "destination_checkpoint_path"
      ],
      "metadata": {
        "id": "MEuDfmGC8LiU",
        "outputId": "7ffdbf4a-4bf1-4799-909f-31210ad05587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "MEuDfmGC8LiU",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/temp/src/checkpoints/best_model.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "papermill": {
          "duration": 0.001736,
          "end_time": "2026-01-06T03:35:23.478842",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.477106",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ceccb6-6117-49ed-979b-b2be996f5bc1",
        "id": "Fqun9L-mIpHd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "INFERENCE ON TEST SET\n",
            "Loading checkpoint from /kaggle/temp/src/checkpoints/best_model.pth...\n",
            "Model loaded\n",
            "\n",
            "Loading test dataset...\n",
            "Test samples: 510\n",
            "\n",
            "Running inference...\n",
            "Processed 160/510 samples\n",
            "Processed 320/510 samples\n",
            "Processed 480/510 samples\n",
            "\n",
            "Inference complete! Processed 510 videos\n",
            "\n",
            "âœ“ Submission file created at: /kaggle/working/submission.csv\n",
            "\n",
            "Submission saved to: /kaggle/working/submission.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python inference.py --checkpoint {destination_checkpoint_path} \\\n",
        "    --data_root {WORKING_DIR}data/test\n",
        "\n",
        "\n"
      ],
      "id": "Fqun9L-mIpHd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submit to Kaggle"
      ],
      "metadata": {
        "id": "uvrvFRHml6Uf"
      },
      "id": "uvrvFRHml6Uf"
    },
    {
      "cell_type": "code",
      "source": [
        "# !Must specify message\n",
        "MESSAGE = \"Testing runbook.ipynb 3rd time\""
      ],
      "metadata": {
        "id": "8Psuu70jmwBX"
      },
      "id": "8Psuu70jmwBX",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c action-video -f /kaggle/working/submission.csv -m \"{MESSAGE}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv0RLRt0jE6y",
        "outputId": "a658ecb6-e9fc-4ead-e429-48bd85a0b1da"
      },
      "id": "bv0RLRt0jE6y",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 3.23k/3.23k [00:00<00:00, 20.0kB/s]\n",
            "Successfully submitted to AIO-2025: Video Action Classification Challenge"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p8NrDcSUlxrj"
      },
      "id": "p8NrDcSUlxrj",
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14910023,
          "sourceId": 125907,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31236,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4.587062,
      "end_time": "2026-01-06T03:35:23.698009",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2026-01-06T03:35:19.110947",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}