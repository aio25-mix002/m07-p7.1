{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ef5c053",
      "metadata": {
        "papermill": {
          "duration": 0.002848,
          "end_time": "2026-01-06T03:35:21.884834",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.881986",
          "status": "completed"
        },
        "tags": [],
        "id": "3ef5c053"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Ic6JDbHAIXph"
      },
      "id": "Ic6JDbHAIXph",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f46f8cc",
      "metadata": {
        "papermill": {
          "duration": 0.00149,
          "end_time": "2026-01-06T03:35:21.887999",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.886509",
          "status": "completed"
        },
        "tags": [],
        "id": "4f46f8cc"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c2fc92c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.892327Z",
          "iopub.status.busy": "2026-01-06T03:35:21.891944Z",
          "iopub.status.idle": "2026-01-06T03:35:21.898008Z",
          "shell.execute_reply": "2026-01-06T03:35:21.897511Z"
        },
        "papermill": {
          "duration": 0.009684,
          "end_time": "2026-01-06T03:35:21.899305",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.889621",
          "status": "completed"
        },
        "tags": [],
        "id": "8c2fc92c"
      },
      "outputs": [],
      "source": [
        "WORKING_DIR = \"/kaggle/working/\"\n",
        "CODE_DIR = \"/kaggle/temp/src\"\n",
        "GDRIVE_DIR = \"/content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshm5WvXIdZB",
        "outputId": "769d18c7-fb0d-43f1-b584-8b148ae827d6"
      },
      "id": "Jshm5WvXIdZB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061a8517",
      "metadata": {
        "papermill": {
          "duration": 0.001467,
          "end_time": "2026-01-06T03:35:21.902523",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.901056",
          "status": "completed"
        },
        "tags": [],
        "id": "061a8517"
      },
      "source": [
        "## Download code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BRANCH = \"ngocdung/make-inference-n-submit\""
      ],
      "metadata": {
        "id": "FFXhOBNLIv0Q"
      },
      "id": "FFXhOBNLIv0Q",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/working/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LerbThkvkplK",
        "outputId": "707e5707-0ddd-44e1-b06b-478ae15ef026"
      },
      "id": "LerbThkvkplK",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/kaggle/working/data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6deb560c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.906915Z",
          "iopub.status.busy": "2026-01-06T03:35:21.906454Z",
          "iopub.status.idle": "2026-01-06T03:35:22.809240Z",
          "shell.execute_reply": "2026-01-06T03:35:22.808363Z"
        },
        "papermill": {
          "duration": 0.906975,
          "end_time": "2026-01-06T03:35:22.811057",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.904082",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6deb560c",
        "outputId": "99acc169-761e-446d-a74f-f891c913aed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/kaggle/temp/src'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 19 (delta 1), reused 10 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (19/19), 21.62 KiB | 21.62 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "# If directory \"src\" not exist then clone a new one\n",
        "!pwd\n",
        "![ -d \"{CODE_DIR}\" ] || git clone --depth 1  --branch \"{BRANCH}\" \"https://github.com/aio25-mix002/m07-p7.1\" \"{CODE_DIR}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1fdc6b4",
      "metadata": {
        "papermill": {
          "duration": 0.002046,
          "end_time": "2026-01-06T03:35:22.814997",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.812951",
          "status": "completed"
        },
        "tags": [],
        "id": "a1fdc6b4"
      },
      "source": [
        "## Fetch the latest code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "29c3a280",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:22.819938Z",
          "iopub.status.busy": "2026-01-06T03:35:22.819676Z",
          "iopub.status.idle": "2026-01-06T03:35:23.462681Z",
          "shell.execute_reply": "2026-01-06T03:35:23.461828Z"
        },
        "papermill": {
          "duration": 0.647535,
          "end_time": "2026-01-06T03:35:23.464347",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.816812",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29c3a280",
        "outputId": "47e0a62d-3601-4bb5-9c2e-9f63af7c4d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/temp/src\n",
            "On branch ngocdung/make-inference-n-submit\n",
            "Your branch is up to date with 'origin/ngocdung/make-inference-n-submit'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Already up to date.\n",
            "/kaggle/temp/src\n"
          ]
        }
      ],
      "source": [
        "# Go to CODE_DIR, Fetch the latest code\n",
        "%cd {CODE_DIR}\n",
        "!git clean -fdx\n",
        "!git status\n",
        "!git pull\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "g4QEb2HlZMiD"
      },
      "id": "g4QEb2HlZMiD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6315fe81"
      },
      "source": [
        "### Option 1: Using Kaggle API Credentials (Only if data in Google Drive not available)\n",
        "\n",
        "First, ensure you have downloaded your `kaggle.json` API token from your Kaggle account. Once downloaded, upload it to your Colab session. You can do this via the 'Files' tab on the left sidebar.\n",
        "\n",
        "After uploading, we will move it to the correct directory (`~/.kaggle/`) and set the necessary permissions."
      ],
      "id": "6315fe81"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "645da322",
        "outputId": "de9ac44d-e893-4678-9273-55fc8405f4bc"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create the .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move the uploaded kaggle.json file to the .kaggle directory\n",
        "# Assuming kaggle.json is in the current working directory after upload\n",
        "# If you uploaded it to a different path, please adjust '/content/kaggle.json'\n",
        "!mv /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print('Kaggle API credentials set up successfully!')\n",
        "!ls -la ~/.kaggle/kaggle.json"
      ],
      "id": "645da322",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API credentials set up successfully!\n",
            "-rw------- 1 root root 67 Jan  9 00:35 /root/.kaggle/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python download_data.py\n",
        "!kaggle competitions download -c action-video\n",
        "!unzip action-video.zip -q -d {WORKING_DIR}"
      ],
      "metadata": {
        "id": "l6odimieZMIC"
      },
      "execution_count": null,
      "outputs": [],
      "id": "l6odimieZMIC"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {WORKING_DIR}data/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSGniFGZZcGU",
        "outputId": "25ab925e-9c1e-4029-c0e2-35276dcf4137"
      },
      "id": "LSGniFGZZcGU",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    127  156  185  213  242  271  30\t329  358  387  415  444  473  501  72\n",
            "1    128  157  186  214  243  272  300\t33   359  388  416  445  474  502  73\n",
            "10   129  158  187  215  244  273  301\t330  36   389  417  446  475  503  74\n",
            "100  13   159  188  216  245  274  302\t331  360  39   418  447  476  504  75\n",
            "101  130  16   189  217  246  275  303\t332  361  390  419  448  477  505  76\n",
            "102  131  160  19   218  247  276  304\t333  362  391  42   449  478  506  77\n",
            "103  132  161  190  219  248  277  305\t334  363  392  420  45\t 479  507  78\n",
            "104  133  162  191  22\t 249  278  306\t335  364  393  421  450  48   508  79\n",
            "105  134  163  192  220  25   279  307\t336  365  394  422  451  480  509  8\n",
            "106  135  164  193  221  250  28   308\t337  366  395  423  452  481  51   80\n",
            "107  136  165  194  222  251  280  309\t338  367  396  424  453  482  52   81\n",
            "108  137  166  195  223  252  281  31\t339  368  397  425  454  483  53   82\n",
            "109  138  167  196  224  253  282  310\t34   369  398  426  455  484  54   83\n",
            "11   139  168  197  225  254  283  311\t340  37   399  427  456  485  55   84\n",
            "110  14   169  198  226  255  284  312\t341  370  4    428  457  486  56   85\n",
            "111  140  17   199  227  256  285  313\t342  371  40   429  458  487  57   86\n",
            "112  141  170  2    228  257  286  314\t343  372  400  43   459  488  58   87\n",
            "113  142  171  20   229  258  287  315\t344  373  401  430  46\t 489  59   88\n",
            "114  143  172  200  23\t 259  288  316\t345  374  402  431  460  49   6    89\n",
            "115  144  173  201  230  26   289  317\t346  375  403  432  461  490  60   9\n",
            "116  145  174  202  231  260  29   318\t347  376  404  433  462  491  61   90\n",
            "117  146  175  203  232  261  290  319\t348  377  405  434  463  492  62   91\n",
            "118  147  176  204  233  262  291  32\t349  378  406  435  464  493  63   92\n",
            "119  148  177  205  234  263  292  320\t35   379  407  436  465  494  64   93\n",
            "12   149  178  206  235  264  293  321\t350  38   408  437  466  495  65   94\n",
            "120  15   179  207  236  265  294  322\t351  380  409  438  467  496  66   95\n",
            "121  150  18   208  237  266  295  323\t352  381  41   439  468  497  67   96\n",
            "122  151  180  209  238  267  296  324\t353  382  410  44   469  498  68   97\n",
            "123  152  181  21   239  268  297  325\t354  383  411  440  47\t 499  69   98\n",
            "124  153  182  210  24\t 269  298  326\t355  384  412  441  470  5    7    99\n",
            "125  154  183  211  240  27   299  327\t356  385  413  442  471  50   70\n",
            "126  155  184  212  241  270  3    328\t357  386  414  443  472  500  71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r /kaggle/working/mini_data.zip /kaggle/working/mini_data\n",
        "!ls -lh {WORKING_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6SxrLVkhpux",
        "outputId": "ff46139c-976f-4eae-9520-48e231e78c47"
      },
      "id": "l6SxrLVkhpux",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 127M\n",
            "drwxr-xr-x 4 root root 4.0K Jan  9 00:39 data\n",
            "drwxr-xr-x 4 root root 4.0K Jan  9 02:11 mini_data\n",
            "-rw-r--r-- 1 root root 127M Jan  9 02:13 mini_data.zip\n",
            "-rw-r--r-- 1 root root 4.4K Dec 12 10:45 submission_template.csv\n",
            "drwxr-xr-x 2 root root 4.0K Jan  9 00:39 weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {WORKING_DIR}data/test/0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUlgLs2Sd66P",
        "outputId": "de6ef5f9-3282-4eb6-f590-e6c7d6100abe"
      },
      "id": "TUlgLs2Sd66P",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000.jpg  10003.jpg  10006.jpg  10009.jpg  10012.jpg  10015.jpg\n",
            "10001.jpg  10004.jpg  10007.jpg  10010.jpg  10013.jpg\n",
            "10002.jpg  10005.jpg  10008.jpg  10011.jpg  10014.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Unused due to synchronizing problem) Option 2: Using data saved in Google Drive\n"
      ],
      "metadata": {
        "id": "lmes98ROmYtp"
      },
      "id": "lmes98ROmYtp"
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# source_gdrive_data_path = os.path.join(GDRIVE_DIR, 'Data')\n",
        "# destination_working_data_path = os.path.join(WORKING_DIR, 'data')\n",
        "\n",
        "# print(f\"Attempting to copy data from Google Drive: {source_gdrive_data_path}\")\n",
        "# print(f\"To working directory: {destination_working_data_path}\")\n",
        "\n",
        "# try:\n",
        "#     # Create the destination directory if it doesn't exist. If it exists, remove it first to avoid errors.\n",
        "#     if os.path.exists(destination_working_data_path):\n",
        "#         print(f\"Destination directory {destination_working_data_path} already exists. Removing before copy...\")\n",
        "#         shutil.rmtree(destination_working_data_path)\n",
        "\n",
        "#     shutil.copytree(source_gdrive_data_path, destination_working_data_path)\n",
        "#     print(f\"Successfully copied '{source_gdrive_data_path}' to '{destination_working_data_path}'\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: Source data directory not found in Google Drive at {source_gdrive_data_path}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred while copying the data from Google Drive: {e}\")"
      ],
      "metadata": {
        "id": "duTIwNE6mYJ-"
      },
      "id": "duTIwNE6mYJ-",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9a407c42",
      "metadata": {
        "papermill": {
          "duration": 0.001813,
          "end_time": "2026-01-06T03:35:23.468110",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.466297",
          "status": "completed"
        },
        "tags": [],
        "id": "9a407c42"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "papermill": {
          "duration": 0.001816,
          "end_time": "2026-01-06T03:35:23.471692",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.469876",
          "status": "completed"
        },
        "tags": [],
        "outputId": "293f8ee9-857f-4afe-d290-a48d97bef432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tt-BYnxIpHa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Initializing datasets...\n",
            "Downloading vit_base_patch16_224 weights via timm...\n",
            "model.safetensors: 100% 346M/346M [00:02<00:00, 126MB/s]\n",
            "Loaded pretrained weights. Missing: 132, Unexpected: 0\n",
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 3.6898 | Acc: 0.0915\n",
            "Val Loss: 3.5272   | Acc: 0.1198\n",
            "New best model saved! (0.1198)\n",
            "\n",
            "Epoch 2/10\n",
            "Train:  41% 579/1407 [05:10<07:22,  1.87it/s, acc=0.1291, loss=3.3721]Exception in thread Thread-5 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 52, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "         ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 519, in Client\n",
            "    c = SocketClient(address)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/multiprocessing/connection.py\", line 647, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "Traceback (most recent call last):\n",
            "  File \"/kaggle/temp/src/train.py\", line 78, in <module>\n",
            "    main()\n",
            "  File \"/kaggle/temp/src/train.py\", line 66, in main\n",
            "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scaler, device)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/kaggle/temp/src/src/engine.py\", line 40, in train_one_epoch\n",
            "    scaler.step(optimizer)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 462, in step\n",
            "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 356, in _maybe_opt_step\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 356, in <genexpr>\n",
            "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
            "               ^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ],
      "id": "6tt-BYnxIpHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the best checkpoint to Google Drive"
      ],
      "metadata": {
        "id": "Ur0NsX_WhB8s"
      },
      "id": "Ur0NsX_WhB8s"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the brief note for the filename\n",
        "NOTE = \"vanilla\" # !!! Should edit every new run\n",
        "SAVE_PATH = f\"{GDRIVE_DIR}Artifacts/Checkpoints\"\n"
      ],
      "metadata": {
        "id": "u_Bun8y2hPnQ"
      },
      "execution_count": 12,
      "outputs": [],
      "id": "u_Bun8y2hPnQ"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the source path of the best model checkpoint\n",
        "source_checkpoint_path = os.path.join(CODE_DIR, 'checkpoints', 'best_model.pth')\n",
        "\n",
        "# Define your Google Drive destination folder path\n",
        "# IMPORTANT: Please replace 'YOUR_GOOGLE_DRIVE_FOLDER_PATH' with the actual path to your folder in Google Drive.\n",
        "# For example, it might be '/content/drive/MyDrive/MyProjectCheckpoints/'\n",
        "\n",
        "# Ensure the Google Drive folder exists\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)\n",
        "    print(f\"Created Google Drive folder: {SAVE_PATH}\")\n",
        "\n",
        "# Generate a timestamp for the filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the new filename for the checkpoint\n",
        "new_checkpoint_filename = f\"model_{timestamp}_{NOTE}.pth\"\n",
        "destination_checkpoint_path = os.path.join(SAVE_PATH, new_checkpoint_filename)\n",
        "\n",
        "# Copy the checkpoint\n",
        "try:\n",
        "    shutil.copy(source_checkpoint_path, destination_checkpoint_path)\n",
        "    print(f\"Checkpoint successfully saved to: {destination_checkpoint_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Source checkpoint not found at {source_checkpoint_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the checkpoint: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mhJA7Kf7VB",
        "outputId": "a4417b5e-3df2-4651-90c9-1fa9fdb47581"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint successfully saved to: /content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/Artifacts/Checkpoints/model_20260109_005840_vanilla.pth\n"
          ]
        }
      ],
      "id": "p-mhJA7Kf7VB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload the checkpoint (if needed)"
      ],
      "metadata": {
        "id": "fRJzvxFzhumr"
      },
      "id": "fRJzvxFzhumr"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# # Define the path to the checkpoint file\n",
        "destination_checkpoint_path = source_checkpoint_path #f'{GDRIVE_DIR}Artifacts/Checkpoints/model_20260107_081244_vanilla.pth'\n",
        "\n",
        "# Check if the checkpoint file exists\n",
        "if os.path.exists(destination_checkpoint_path):\n",
        "    # Load the checkpoint\n",
        "    loaded_checkpoint = torch.load(destination_checkpoint_path, map_location=torch.device('cpu')) # Use 'cuda' if you want to load to GPU\n",
        "    print(f\"Checkpoint loaded successfully from: {destination_checkpoint_path}\")\n",
        "    print(\"Keys in the loaded checkpoint:\", loaded_checkpoint.keys())\n",
        "\n",
        "    # Example of how you might load it into a model (assuming 'model' is defined)\n",
        "    # model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
        "    # epoch = loaded_checkpoint['epoch']\n",
        "    # loss = loaded_checkpoint['loss']\n",
        "else:\n",
        "    print(f\"Error: Checkpoint not found at {destination_checkpoint_path}\")\n"
      ],
      "metadata": {
        "id": "l3UZYdnshyZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a63fd4-409f-44f9-b345-1f75ccdf62c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded successfully from: /kaggle/temp/src/checkpoints/best_model.pth\n",
            "Keys in the loaded checkpoint: odict_keys(['smif.alpha', 'smif.conv_fuse.weight', 'smif.conv_fuse.bias', 'backbone.cls_token', 'backbone.pos_embed', 'backbone.patch_embed.proj.weight', 'backbone.patch_embed.proj.bias', 'backbone.blocks.0.norm1.weight', 'backbone.blocks.0.norm1.bias', 'backbone.blocks.0.attn.qkv.weight', 'backbone.blocks.0.attn.qkv.bias', 'backbone.blocks.0.attn.proj.weight', 'backbone.blocks.0.attn.proj.bias', 'backbone.blocks.0.norm2.weight', 'backbone.blocks.0.norm2.bias', 'backbone.blocks.0.mlp.fc1.weight', 'backbone.blocks.0.mlp.fc1.bias', 'backbone.blocks.0.mlp.fc2.weight', 'backbone.blocks.0.mlp.fc2.bias', 'backbone.blocks.0.lmim.delta', 'backbone.blocks.0.lmim.reduce.weight', 'backbone.blocks.0.lmim.reduce.bias', 'backbone.blocks.0.lmim.expand.weight', 'backbone.blocks.0.lmim.expand.bias', 'backbone.blocks.0.lmim.temporal_mlp.0.weight', 'backbone.blocks.0.lmim.temporal_mlp.0.bias', 'backbone.blocks.0.lmim.temporal_mlp.1.weight', 'backbone.blocks.0.lmim.temporal_mlp.1.bias', 'backbone.blocks.0.lmim.temporal_mlp.3.weight', 'backbone.blocks.0.lmim.temporal_mlp.3.bias', 'backbone.blocks.1.norm1.weight', 'backbone.blocks.1.norm1.bias', 'backbone.blocks.1.attn.qkv.weight', 'backbone.blocks.1.attn.qkv.bias', 'backbone.blocks.1.attn.proj.weight', 'backbone.blocks.1.attn.proj.bias', 'backbone.blocks.1.norm2.weight', 'backbone.blocks.1.norm2.bias', 'backbone.blocks.1.mlp.fc1.weight', 'backbone.blocks.1.mlp.fc1.bias', 'backbone.blocks.1.mlp.fc2.weight', 'backbone.blocks.1.mlp.fc2.bias', 'backbone.blocks.1.lmim.delta', 'backbone.blocks.1.lmim.reduce.weight', 'backbone.blocks.1.lmim.reduce.bias', 'backbone.blocks.1.lmim.expand.weight', 'backbone.blocks.1.lmim.expand.bias', 'backbone.blocks.1.lmim.temporal_mlp.0.weight', 'backbone.blocks.1.lmim.temporal_mlp.0.bias', 'backbone.blocks.1.lmim.temporal_mlp.1.weight', 'backbone.blocks.1.lmim.temporal_mlp.1.bias', 'backbone.blocks.1.lmim.temporal_mlp.3.weight', 'backbone.blocks.1.lmim.temporal_mlp.3.bias', 'backbone.blocks.2.norm1.weight', 'backbone.blocks.2.norm1.bias', 'backbone.blocks.2.attn.qkv.weight', 'backbone.blocks.2.attn.qkv.bias', 'backbone.blocks.2.attn.proj.weight', 'backbone.blocks.2.attn.proj.bias', 'backbone.blocks.2.norm2.weight', 'backbone.blocks.2.norm2.bias', 'backbone.blocks.2.mlp.fc1.weight', 'backbone.blocks.2.mlp.fc1.bias', 'backbone.blocks.2.mlp.fc2.weight', 'backbone.blocks.2.mlp.fc2.bias', 'backbone.blocks.2.lmim.delta', 'backbone.blocks.2.lmim.reduce.weight', 'backbone.blocks.2.lmim.reduce.bias', 'backbone.blocks.2.lmim.expand.weight', 'backbone.blocks.2.lmim.expand.bias', 'backbone.blocks.2.lmim.temporal_mlp.0.weight', 'backbone.blocks.2.lmim.temporal_mlp.0.bias', 'backbone.blocks.2.lmim.temporal_mlp.1.weight', 'backbone.blocks.2.lmim.temporal_mlp.1.bias', 'backbone.blocks.2.lmim.temporal_mlp.3.weight', 'backbone.blocks.2.lmim.temporal_mlp.3.bias', 'backbone.blocks.3.norm1.weight', 'backbone.blocks.3.norm1.bias', 'backbone.blocks.3.attn.qkv.weight', 'backbone.blocks.3.attn.qkv.bias', 'backbone.blocks.3.attn.proj.weight', 'backbone.blocks.3.attn.proj.bias', 'backbone.blocks.3.norm2.weight', 'backbone.blocks.3.norm2.bias', 'backbone.blocks.3.mlp.fc1.weight', 'backbone.blocks.3.mlp.fc1.bias', 'backbone.blocks.3.mlp.fc2.weight', 'backbone.blocks.3.mlp.fc2.bias', 'backbone.blocks.3.lmim.delta', 'backbone.blocks.3.lmim.reduce.weight', 'backbone.blocks.3.lmim.reduce.bias', 'backbone.blocks.3.lmim.expand.weight', 'backbone.blocks.3.lmim.expand.bias', 'backbone.blocks.3.lmim.temporal_mlp.0.weight', 'backbone.blocks.3.lmim.temporal_mlp.0.bias', 'backbone.blocks.3.lmim.temporal_mlp.1.weight', 'backbone.blocks.3.lmim.temporal_mlp.1.bias', 'backbone.blocks.3.lmim.temporal_mlp.3.weight', 'backbone.blocks.3.lmim.temporal_mlp.3.bias', 'backbone.blocks.4.norm1.weight', 'backbone.blocks.4.norm1.bias', 'backbone.blocks.4.attn.qkv.weight', 'backbone.blocks.4.attn.qkv.bias', 'backbone.blocks.4.attn.proj.weight', 'backbone.blocks.4.attn.proj.bias', 'backbone.blocks.4.norm2.weight', 'backbone.blocks.4.norm2.bias', 'backbone.blocks.4.mlp.fc1.weight', 'backbone.blocks.4.mlp.fc1.bias', 'backbone.blocks.4.mlp.fc2.weight', 'backbone.blocks.4.mlp.fc2.bias', 'backbone.blocks.4.lmim.delta', 'backbone.blocks.4.lmim.reduce.weight', 'backbone.blocks.4.lmim.reduce.bias', 'backbone.blocks.4.lmim.expand.weight', 'backbone.blocks.4.lmim.expand.bias', 'backbone.blocks.4.lmim.temporal_mlp.0.weight', 'backbone.blocks.4.lmim.temporal_mlp.0.bias', 'backbone.blocks.4.lmim.temporal_mlp.1.weight', 'backbone.blocks.4.lmim.temporal_mlp.1.bias', 'backbone.blocks.4.lmim.temporal_mlp.3.weight', 'backbone.blocks.4.lmim.temporal_mlp.3.bias', 'backbone.blocks.5.norm1.weight', 'backbone.blocks.5.norm1.bias', 'backbone.blocks.5.attn.qkv.weight', 'backbone.blocks.5.attn.qkv.bias', 'backbone.blocks.5.attn.proj.weight', 'backbone.blocks.5.attn.proj.bias', 'backbone.blocks.5.norm2.weight', 'backbone.blocks.5.norm2.bias', 'backbone.blocks.5.mlp.fc1.weight', 'backbone.blocks.5.mlp.fc1.bias', 'backbone.blocks.5.mlp.fc2.weight', 'backbone.blocks.5.mlp.fc2.bias', 'backbone.blocks.5.lmim.delta', 'backbone.blocks.5.lmim.reduce.weight', 'backbone.blocks.5.lmim.reduce.bias', 'backbone.blocks.5.lmim.expand.weight', 'backbone.blocks.5.lmim.expand.bias', 'backbone.blocks.5.lmim.temporal_mlp.0.weight', 'backbone.blocks.5.lmim.temporal_mlp.0.bias', 'backbone.blocks.5.lmim.temporal_mlp.1.weight', 'backbone.blocks.5.lmim.temporal_mlp.1.bias', 'backbone.blocks.5.lmim.temporal_mlp.3.weight', 'backbone.blocks.5.lmim.temporal_mlp.3.bias', 'backbone.blocks.6.norm1.weight', 'backbone.blocks.6.norm1.bias', 'backbone.blocks.6.attn.qkv.weight', 'backbone.blocks.6.attn.qkv.bias', 'backbone.blocks.6.attn.proj.weight', 'backbone.blocks.6.attn.proj.bias', 'backbone.blocks.6.norm2.weight', 'backbone.blocks.6.norm2.bias', 'backbone.blocks.6.mlp.fc1.weight', 'backbone.blocks.6.mlp.fc1.bias', 'backbone.blocks.6.mlp.fc2.weight', 'backbone.blocks.6.mlp.fc2.bias', 'backbone.blocks.6.lmim.delta', 'backbone.blocks.6.lmim.reduce.weight', 'backbone.blocks.6.lmim.reduce.bias', 'backbone.blocks.6.lmim.expand.weight', 'backbone.blocks.6.lmim.expand.bias', 'backbone.blocks.6.lmim.temporal_mlp.0.weight', 'backbone.blocks.6.lmim.temporal_mlp.0.bias', 'backbone.blocks.6.lmim.temporal_mlp.1.weight', 'backbone.blocks.6.lmim.temporal_mlp.1.bias', 'backbone.blocks.6.lmim.temporal_mlp.3.weight', 'backbone.blocks.6.lmim.temporal_mlp.3.bias', 'backbone.blocks.7.norm1.weight', 'backbone.blocks.7.norm1.bias', 'backbone.blocks.7.attn.qkv.weight', 'backbone.blocks.7.attn.qkv.bias', 'backbone.blocks.7.attn.proj.weight', 'backbone.blocks.7.attn.proj.bias', 'backbone.blocks.7.norm2.weight', 'backbone.blocks.7.norm2.bias', 'backbone.blocks.7.mlp.fc1.weight', 'backbone.blocks.7.mlp.fc1.bias', 'backbone.blocks.7.mlp.fc2.weight', 'backbone.blocks.7.mlp.fc2.bias', 'backbone.blocks.7.lmim.delta', 'backbone.blocks.7.lmim.reduce.weight', 'backbone.blocks.7.lmim.reduce.bias', 'backbone.blocks.7.lmim.expand.weight', 'backbone.blocks.7.lmim.expand.bias', 'backbone.blocks.7.lmim.temporal_mlp.0.weight', 'backbone.blocks.7.lmim.temporal_mlp.0.bias', 'backbone.blocks.7.lmim.temporal_mlp.1.weight', 'backbone.blocks.7.lmim.temporal_mlp.1.bias', 'backbone.blocks.7.lmim.temporal_mlp.3.weight', 'backbone.blocks.7.lmim.temporal_mlp.3.bias', 'backbone.blocks.8.norm1.weight', 'backbone.blocks.8.norm1.bias', 'backbone.blocks.8.attn.qkv.weight', 'backbone.blocks.8.attn.qkv.bias', 'backbone.blocks.8.attn.proj.weight', 'backbone.blocks.8.attn.proj.bias', 'backbone.blocks.8.norm2.weight', 'backbone.blocks.8.norm2.bias', 'backbone.blocks.8.mlp.fc1.weight', 'backbone.blocks.8.mlp.fc1.bias', 'backbone.blocks.8.mlp.fc2.weight', 'backbone.blocks.8.mlp.fc2.bias', 'backbone.blocks.8.lmim.delta', 'backbone.blocks.8.lmim.reduce.weight', 'backbone.blocks.8.lmim.reduce.bias', 'backbone.blocks.8.lmim.expand.weight', 'backbone.blocks.8.lmim.expand.bias', 'backbone.blocks.8.lmim.temporal_mlp.0.weight', 'backbone.blocks.8.lmim.temporal_mlp.0.bias', 'backbone.blocks.8.lmim.temporal_mlp.1.weight', 'backbone.blocks.8.lmim.temporal_mlp.1.bias', 'backbone.blocks.8.lmim.temporal_mlp.3.weight', 'backbone.blocks.8.lmim.temporal_mlp.3.bias', 'backbone.blocks.9.norm1.weight', 'backbone.blocks.9.norm1.bias', 'backbone.blocks.9.attn.qkv.weight', 'backbone.blocks.9.attn.qkv.bias', 'backbone.blocks.9.attn.proj.weight', 'backbone.blocks.9.attn.proj.bias', 'backbone.blocks.9.norm2.weight', 'backbone.blocks.9.norm2.bias', 'backbone.blocks.9.mlp.fc1.weight', 'backbone.blocks.9.mlp.fc1.bias', 'backbone.blocks.9.mlp.fc2.weight', 'backbone.blocks.9.mlp.fc2.bias', 'backbone.blocks.9.lmim.delta', 'backbone.blocks.9.lmim.reduce.weight', 'backbone.blocks.9.lmim.reduce.bias', 'backbone.blocks.9.lmim.expand.weight', 'backbone.blocks.9.lmim.expand.bias', 'backbone.blocks.9.lmim.temporal_mlp.0.weight', 'backbone.blocks.9.lmim.temporal_mlp.0.bias', 'backbone.blocks.9.lmim.temporal_mlp.1.weight', 'backbone.blocks.9.lmim.temporal_mlp.1.bias', 'backbone.blocks.9.lmim.temporal_mlp.3.weight', 'backbone.blocks.9.lmim.temporal_mlp.3.bias', 'backbone.blocks.10.norm1.weight', 'backbone.blocks.10.norm1.bias', 'backbone.blocks.10.attn.qkv.weight', 'backbone.blocks.10.attn.qkv.bias', 'backbone.blocks.10.attn.proj.weight', 'backbone.blocks.10.attn.proj.bias', 'backbone.blocks.10.norm2.weight', 'backbone.blocks.10.norm2.bias', 'backbone.blocks.10.mlp.fc1.weight', 'backbone.blocks.10.mlp.fc1.bias', 'backbone.blocks.10.mlp.fc2.weight', 'backbone.blocks.10.mlp.fc2.bias', 'backbone.blocks.10.lmim.delta', 'backbone.blocks.10.lmim.reduce.weight', 'backbone.blocks.10.lmim.reduce.bias', 'backbone.blocks.10.lmim.expand.weight', 'backbone.blocks.10.lmim.expand.bias', 'backbone.blocks.10.lmim.temporal_mlp.0.weight', 'backbone.blocks.10.lmim.temporal_mlp.0.bias', 'backbone.blocks.10.lmim.temporal_mlp.1.weight', 'backbone.blocks.10.lmim.temporal_mlp.1.bias', 'backbone.blocks.10.lmim.temporal_mlp.3.weight', 'backbone.blocks.10.lmim.temporal_mlp.3.bias', 'backbone.blocks.11.norm1.weight', 'backbone.blocks.11.norm1.bias', 'backbone.blocks.11.attn.qkv.weight', 'backbone.blocks.11.attn.qkv.bias', 'backbone.blocks.11.attn.proj.weight', 'backbone.blocks.11.attn.proj.bias', 'backbone.blocks.11.norm2.weight', 'backbone.blocks.11.norm2.bias', 'backbone.blocks.11.mlp.fc1.weight', 'backbone.blocks.11.mlp.fc1.bias', 'backbone.blocks.11.mlp.fc2.weight', 'backbone.blocks.11.mlp.fc2.bias', 'backbone.blocks.11.lmim.delta', 'backbone.blocks.11.lmim.reduce.weight', 'backbone.blocks.11.lmim.reduce.bias', 'backbone.blocks.11.lmim.expand.weight', 'backbone.blocks.11.lmim.expand.bias', 'backbone.blocks.11.lmim.temporal_mlp.0.weight', 'backbone.blocks.11.lmim.temporal_mlp.0.bias', 'backbone.blocks.11.lmim.temporal_mlp.1.weight', 'backbone.blocks.11.lmim.temporal_mlp.1.bias', 'backbone.blocks.11.lmim.temporal_mlp.3.weight', 'backbone.blocks.11.lmim.temporal_mlp.3.bias', 'backbone.norm.weight', 'backbone.norm.bias', 'head.weight', 'head.bias'])\n"
          ]
        }
      ],
      "id": "l3UZYdnshyZf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.001777,
          "end_time": "2026-01-06T03:35:23.475387",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.473610",
          "status": "completed"
        },
        "tags": [],
        "id": "mtDjbSeWIpHc"
      },
      "source": [
        "# Submission"
      ],
      "id": "mtDjbSeWIpHc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference of Test set"
      ],
      "metadata": {
        "id": "yOgglTaiiX8E"
      },
      "id": "yOgglTaiiX8E"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "papermill": {
          "duration": 0.001736,
          "end_time": "2026-01-06T03:35:23.478842",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.477106",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64999ed5-c3a6-441a-ea32-7a6d10ce8b26",
        "id": "Fqun9L-mIpHd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "INFERENCE ON TEST SET\n",
            "Loading checkpoint from /kaggle/temp/src/checkpoints/best_model.pth...\n",
            "Model loaded\n",
            "\n",
            "Loading test dataset...\n",
            "Test samples: 0\n"
          ]
        }
      ],
      "source": [
        "!python inference.py --checkpoint {destination_checkpoint_path} --data_root {WORKING_DIR}data/test"
      ],
      "id": "Fqun9L-mIpHd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make submission file and submit to Kaggle"
      ],
      "metadata": {
        "id": "sblI1-oItK2J"
      },
      "id": "sblI1-oItK2J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e396697a",
      "metadata": {
        "papermill": {
          "duration": 0.001736,
          "end_time": "2026-01-06T03:35:23.478842",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.477106",
          "status": "completed"
        },
        "tags": [],
        "id": "e396697a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14910023,
          "sourceId": 125907,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31236,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4.587062,
      "end_time": "2026-01-06T03:35:23.698009",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2026-01-06T03:35:19.110947",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}