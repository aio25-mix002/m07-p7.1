{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ef5c053",
      "metadata": {
        "papermill": {
          "duration": 0.002848,
          "end_time": "2026-01-06T03:35:21.884834",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.881986",
          "status": "completed"
        },
        "tags": [],
        "id": "3ef5c053"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Ic6JDbHAIXph"
      },
      "id": "Ic6JDbHAIXph",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f46f8cc",
      "metadata": {
        "papermill": {
          "duration": 0.00149,
          "end_time": "2026-01-06T03:35:21.887999",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.886509",
          "status": "completed"
        },
        "tags": [],
        "id": "4f46f8cc"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c2fc92c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.892327Z",
          "iopub.status.busy": "2026-01-06T03:35:21.891944Z",
          "iopub.status.idle": "2026-01-06T03:35:21.898008Z",
          "shell.execute_reply": "2026-01-06T03:35:21.897511Z"
        },
        "papermill": {
          "duration": 0.009684,
          "end_time": "2026-01-06T03:35:21.899305",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.889621",
          "status": "completed"
        },
        "tags": [],
        "id": "8c2fc92c"
      },
      "outputs": [],
      "source": [
        "WORKING_DIR = \"/kaggle/working/\"\n",
        "CODE_DIR = \"/kaggle/temp/src\"\n",
        "GDRIVE_DIR = \"/content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshm5WvXIdZB",
        "outputId": "a762ea4d-4ce2-4c0d-cbed-f8e4a08721cc"
      },
      "id": "Jshm5WvXIdZB",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061a8517",
      "metadata": {
        "papermill": {
          "duration": 0.001467,
          "end_time": "2026-01-06T03:35:21.902523",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.901056",
          "status": "completed"
        },
        "tags": [],
        "id": "061a8517"
      },
      "source": [
        "## Download code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! Change branch name if not main\n",
        "BRANCH = \"ngocdung/model-improvement\""
      ],
      "metadata": {
        "id": "FFXhOBNLIv0Q"
      },
      "id": "FFXhOBNLIv0Q",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6deb560c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.906915Z",
          "iopub.status.busy": "2026-01-06T03:35:21.906454Z",
          "iopub.status.idle": "2026-01-06T03:35:22.809240Z",
          "shell.execute_reply": "2026-01-06T03:35:22.808363Z"
        },
        "papermill": {
          "duration": 0.906975,
          "end_time": "2026-01-06T03:35:22.811057",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.904082",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6deb560c",
        "outputId": "36d8b85d-b429-4886-a79c-b1cde1dd90e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/kaggle/temp/src'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 23 (delta 1), reused 13 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (23/23), 41.89 KiB | 2.99 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "# If directory \"src\" not exist then clone a new one\n",
        "!pwd\n",
        "![ -d \"{CODE_DIR}\" ] || git clone --depth 1  --branch \"{BRANCH}\" \"https://github.com/aio25-mix002/m07-p7.1\" \"{CODE_DIR}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1fdc6b4",
      "metadata": {
        "papermill": {
          "duration": 0.002046,
          "end_time": "2026-01-06T03:35:22.814997",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.812951",
          "status": "completed"
        },
        "tags": [],
        "id": "a1fdc6b4"
      },
      "source": [
        "## Fetch the latest code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "29c3a280",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:22.819938Z",
          "iopub.status.busy": "2026-01-06T03:35:22.819676Z",
          "iopub.status.idle": "2026-01-06T03:35:23.462681Z",
          "shell.execute_reply": "2026-01-06T03:35:23.461828Z"
        },
        "papermill": {
          "duration": 0.647535,
          "end_time": "2026-01-06T03:35:23.464347",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.816812",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29c3a280",
        "outputId": "b0c86c12-b3cf-493a-c19f-67d9619f49c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/temp/src\n",
            "On branch ngocdung/model-improvement\n",
            "Your branch is up to date with 'origin/ngocdung/model-improvement'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Already up to date.\n",
            "/kaggle/temp/src\n"
          ]
        }
      ],
      "source": [
        "# Go to CODE_DIR, Fetch the latest code\n",
        "%cd {CODE_DIR}\n",
        "!git clean -fdx\n",
        "!git status\n",
        "!git pull\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "g4QEb2HlZMiD"
      },
      "id": "g4QEb2HlZMiD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6315fe81"
      },
      "source": [
        "### Option 1: Using Kaggle API Credentials (Only if data in Google Drive not available)\n",
        "\n",
        "First, ensure you have downloaded your `kaggle.json` API token from your Kaggle account. Once downloaded, upload it to your Colab session. You can do this via the 'Files' tab on the left sidebar.\n",
        "\n",
        "After uploading, we will move it to the correct directory (`~/.kaggle/`) and set the necessary permissions."
      ],
      "id": "6315fe81"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "645da322",
        "outputId": "a33fcd25-3fe5-4789-814b-d7efaed116cd"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create the .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move the uploaded kaggle.json file to the .kaggle directory\n",
        "# Assuming kaggle.json is in the current working directory after upload\n",
        "# If you uploaded it to a different path, please adjust '/content/kaggle.json'\n",
        "!mv /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print('Kaggle API credentials set up successfully!')\n",
        "!ls -la ~/.kaggle/kaggle.json"
      ],
      "id": "645da322",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API credentials set up successfully!\n",
            "-rw------- 1 root root 67 Jan 10 12:13 /root/.kaggle/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python download_data.py\n",
        "!kaggle competitions download -c action-video\n",
        "!unzip -q action-video.zip  -d {WORKING_DIR}"
      ],
      "metadata": {
        "id": "l6odimieZMIC",
        "outputId": "5acbae1f-7e6f-43dd-98ae-26b9802fdf44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading action-video.zip to /kaggle/temp/src\n",
            " 98% 3.07G/3.14G [00:08<00:00, 611MB/s]\n",
            "100% 3.14G/3.14G [00:08<00:00, 388MB/s]\n"
          ]
        }
      ],
      "id": "l6odimieZMIC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Unused due to synchronizing problem) Option 2: Using data saved in Google Drive\n"
      ],
      "metadata": {
        "id": "lmes98ROmYtp"
      },
      "id": "lmes98ROmYtp"
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# source_gdrive_data_path = os.path.join(GDRIVE_DIR, 'Data')\n",
        "# destination_working_data_path = os.path.join(WORKING_DIR, 'data')\n",
        "\n",
        "# print(f\"Attempting to copy data from Google Drive: {source_gdrive_data_path}\")\n",
        "# print(f\"To working directory: {destination_working_data_path}\")\n",
        "\n",
        "# try:\n",
        "#     # Create the destination directory if it doesn't exist. If it exists, remove it first to avoid errors.\n",
        "#     if os.path.exists(destination_working_data_path):\n",
        "#         print(f\"Destination directory {destination_working_data_path} already exists. Removing before copy...\")\n",
        "#         shutil.rmtree(destination_working_data_path)\n",
        "\n",
        "#     shutil.copytree(source_gdrive_data_path, destination_working_data_path)\n",
        "#     print(f\"Successfully copied '{source_gdrive_data_path}' to '{destination_working_data_path}'\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: Source data directory not found in Google Drive at {source_gdrive_data_path}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred while copying the data from Google Drive: {e}\")"
      ],
      "metadata": {
        "id": "duTIwNE6mYJ-"
      },
      "id": "duTIwNE6mYJ-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sh {CODE_DIR}/quick_train.sh"
      ],
      "metadata": {
        "id": "VXx_ZZvgZA5q"
      },
      "id": "VXx_ZZvgZA5q",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9a407c42",
      "metadata": {
        "papermill": {
          "duration": 0.001813,
          "end_time": "2026-01-06T03:35:23.468110",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.466297",
          "status": "completed"
        },
        "tags": [],
        "id": "9a407c42"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "CeiM2_IIk9wX"
      },
      "id": "CeiM2_IIk9wX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint to resume\n",
        "ckt_path = f\"{GDRIVE_DIR}Artifacts/Checkpoints/model_20260109_141854_3dpatch.pth\""
      ],
      "metadata": {
        "id": "Z00MWujz0fF7"
      },
      "id": "Z00MWujz0fF7",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_improved.py \\\n",
        "  --resume {ckt_path} \\\n",
        "  --epochs 20 \\\n",
        "  --lr 1e-4 \\\n",
        "  --backbone_lr 1e-5 \\\n",
        "  --weight_decay 0.05 \\\n",
        "  --lr_scheduler plateau \\\n",
        "  --freeze_epochs 0 \\\n",
        "  --early_stopping_patience 8 \\\n",
        "  --val_ratio 0.15 \\\n",
        "  --checkpoint_dir ./checkpoints_improved"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qPQY2UOybMw",
        "outputId": "70e75403-fce1-4fef-9afb-77096b38a5c6"
      },
      "id": "_qPQY2UOybMw",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ–¥ï¸  Using device: cuda\n",
            "\n",
            "ðŸ“ Initializing datasets...\n",
            "âœ… Train size: 5315 | Val size: 939\n",
            "\n",
            "ðŸ¤– Creating model...\n",
            "ðŸš€ Compiling model with torch.compile...\n",
            "ðŸ“Š Optimizer config:\n",
            "   Head/SMIF LR: 0.0001\n",
            "   Backbone LR: 1e-05\n",
            "   Weight decay: 0.05\n",
            "ðŸ“ˆ Using ReduceLROnPlateau scheduler (patience=3)\n",
            "\n",
            "ðŸ“‚ Loading checkpoint from: /content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/Artifacts/Checkpoints/model_20260109_141854_3dpatch.pth\n",
            "âœ… Loaded model weights only\n",
            "\n",
            "======================================================================\n",
            "ðŸŽ¯ Training Configuration:\n",
            "======================================================================\n",
            "  Epochs: 20 (starting from 0)\n",
            "  Batch size: 8\n",
            "  Learning rate: 1.00e-04 (head/SMIF), 1.00e-05 (backbone)\n",
            "  Weight decay: 0.05\n",
            "  Num frames: 16\n",
            "  Frame stride: 2\n",
            "  Val ratio: 0.15\n",
            "  Freeze epochs: 0\n",
            "  LR scheduler: plateau\n",
            "  Warmup epochs: 2\n",
            "  Early stopping patience: 8\n",
            "  Checkpoint dir: ./checkpoints_improved\n",
            "  Resume from: /content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/Artifacts/Checkpoints/model_20260109_141854_3dpatch.pth\n",
            "======================================================================\n",
            "\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "ðŸ”¥ Warmup epoch 1/2 - LR: 5.00e-05\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 1/20\n",
            "======================================================================\n",
            "Train:   0% 0/665 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n",
            "W0110 12:16:17.353000 2474 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "Val:   0% 0/118 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py:312: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 1.4370 | Train Acc: 0.6026\n",
            "   Val Loss:   1.8441 | Val Acc:   0.5133\n",
            "   Best Val Acc: 0.0000\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_1.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.5133)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "ðŸ”¥ Warmup epoch 2/2 - LR: 1.00e-04\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 2/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 1.1783 | Train Acc: 0.6623\n",
            "   Val Loss:   1.5763 | Val Acc:   0.6060\n",
            "   Best Val Acc: 0.5133\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_2.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.6060)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 3/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.8529 | Train Acc: 0.7473\n",
            "   Val Loss:   1.4773 | Val Acc:   0.6155\n",
            "   Best Val Acc: 0.6060\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_3.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.6155)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 4/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.6447 | Train Acc: 0.8109\n",
            "   Val Loss:   1.3891 | Val Acc:   0.6571\n",
            "   Best Val Acc: 0.6155\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_4.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.6571)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 5/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.4999 | Train Acc: 0.8472\n",
            "   Val Loss:   1.3721 | Val Acc:   0.6720\n",
            "   Best Val Acc: 0.6571\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_5.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.6720)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 6/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.3775 | Train Acc: 0.8824\n",
            "   Val Loss:   1.3674 | Val Acc:   0.6880\n",
            "   Best Val Acc: 0.6720\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_6.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.6880)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 7/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.3133 | Train Acc: 0.9037\n",
            "   Val Loss:   1.4001 | Val Acc:   0.6816\n",
            "   Best Val Acc: 0.6880\n",
            "   Current LR: 1.00e-04\n",
            "   â³ Patience: 1/8\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 8/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.2339 | Train Acc: 0.9276\n",
            "   Val Loss:   1.4222 | Val Acc:   0.6858\n",
            "   Best Val Acc: 0.6880\n",
            "   Current LR: 1.00e-04\n",
            "   â³ Patience: 2/8\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 9/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.1921 | Train Acc: 0.9451\n",
            "   Val Loss:   1.4152 | Val Acc:   0.6954\n",
            "   Best Val Acc: 0.6880\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_9.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.6954)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 10/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.1704 | Train Acc: 0.9494\n",
            "   Val Loss:   1.4285 | Val Acc:   0.7029\n",
            "   Best Val Acc: 0.6954\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_10.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.7029)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 11/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.1459 | Train Acc: 0.9569\n",
            "   Val Loss:   1.5290 | Val Acc:   0.6858\n",
            "   Best Val Acc: 0.7029\n",
            "   Current LR: 1.00e-04\n",
            "   â³ Patience: 1/8\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 12/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.1248 | Train Acc: 0.9644\n",
            "   Val Loss:   1.4978 | Val Acc:   0.7103\n",
            "   Best Val Acc: 0.7029\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_12.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.7103)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 13/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.1077 | Train Acc: 0.9691\n",
            "   Val Loss:   1.6345 | Val Acc:   0.6965\n",
            "   Best Val Acc: 0.7103\n",
            "   Current LR: 1.00e-04\n",
            "   â³ Patience: 1/8\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 14/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.0974 | Train Acc: 0.9727\n",
            "   Val Loss:   1.5237 | Val Acc:   0.7199\n",
            "   Best Val Acc: 0.7103\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_14.pth\n",
            "ðŸ† New best model saved: ./checkpoints_improved/best_model.pth (acc: 0.7199)\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 15/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.1011 | Train Acc: 0.9710\n",
            "   Val Loss:   1.6803 | Val Acc:   0.7146\n",
            "   Best Val Acc: 0.7199\n",
            "   Current LR: 1.00e-04\n",
            "ðŸ’¾ Saved checkpoint: ./checkpoints_improved/checkpoint_epoch_15.pth\n",
            "   â³ Patience: 1/8\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 16/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.0828 | Train Acc: 0.9797\n",
            "   Val Loss:   1.6899 | Val Acc:   0.7071\n",
            "   Best Val Acc: 0.7199\n",
            "   Current LR: 1.00e-04\n",
            "   â³ Patience: 2/8\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 17/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.0782 | Train Acc: 0.9765\n",
            "   Val Loss:   1.6702 | Val Acc:   0.7071\n",
            "   Best Val Acc: 0.7199\n",
            "   Current LR: 1.00e-04\n",
            "   â³ Patience: 3/8\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 18/20\n",
            "======================================================================\n",
            "                                          \n",
            "ðŸ“Š Results:\n",
            "   Train Loss: 0.0824 | Train Acc: 0.9787\n",
            "   Val Loss:   1.7193 | Val Acc:   0.7093\n",
            "   Best Val Acc: 0.7199\n",
            "   Current LR: 5.00e-05\n",
            "   â³ Patience: 4/8\n",
            "ðŸ”“ Backbone UNFROZEN (Training full model)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“… Epoch 19/20\n",
            "======================================================================\n",
            "Traceback (most recent call last):\n",
            "  File \"/kaggle/temp/src/train_improved.py\", line 415, in <module>\n",
            "    main()\n",
            "  File \"/kaggle/temp/src/train_improved.py\", line 352, in main\n",
            "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, scaler, device)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/kaggle/temp/src/src/engine.py\", line 31, in train_one_epoch\n",
            "    correct += (preds == labels).sum().item()\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "papermill": {
          "duration": 0.001816,
          "end_time": "2026-01-06T03:35:23.471692",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.469876",
          "status": "completed"
        },
        "tags": [],
        "id": "6tt-BYnxIpHa"
      },
      "outputs": [],
      "source": [
        "# # Training - can change number of epochs\n",
        "# # !python train.py #--epochs 1\n",
        "\n",
        "# # Enable 3D patch embedding\n",
        "# !export APPCONFIG__USE_3D_PATCH_EMBED=true\n",
        "\n",
        "# # Set temporal patch size (tubelet size)\n",
        "# !export APPCONFIG__TUBELET_SIZE=2  # Common values: 1, 2, 4\n",
        "\n",
        "# # Spatial patch size (same as before)\n",
        "# !export APPCONFIG__PATCH_SIZE=16\n",
        "\n",
        "# # Set environment variable\n",
        "# !export APPCONFIG__USE_3D_PATCH_EMBED=true\n",
        "# !export APPCONFIG__TUBELET_SIZE=2\n",
        "\n",
        "# # Run training\n",
        "# !python train.py --num_frames 16 --epochs 1"
      ],
      "id": "6tt-BYnxIpHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the best checkpoint to Google Drive"
      ],
      "metadata": {
        "id": "Ur0NsX_WhB8s"
      },
      "id": "Ur0NsX_WhB8s"
    },
    {
      "cell_type": "code",
      "source": [
        "f\"{GDRIVE_DIR}Artifacts/Checkpoints\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5gJayomUgDGP",
        "outputId": "817d6936-017b-46e5-ff29-4604cca34a29"
      },
      "id": "5gJayomUgDGP",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/Artifacts/Checkpoints'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the brief note for the filename\n",
        "NOTE = \"3dreg\" # !!! Should edit every new run\n",
        "SAVE_PATH = f\"{GDRIVE_DIR}Artifacts/Checkpoints\"\n"
      ],
      "metadata": {
        "id": "u_Bun8y2hPnQ"
      },
      "execution_count": 21,
      "outputs": [],
      "id": "u_Bun8y2hPnQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the source path of the best model checkpoint\n",
        "source_checkpoint_path = os.path.join(CODE_DIR, 'checkpoints_improved', 'best_model.pth')\n",
        "\n",
        "# Define your Google Drive destination folder path\n",
        "# IMPORTANT: Please replace 'YOUR_GOOGLE_DRIVE_FOLDER_PATH' with the actual path to your folder in Google Drive.\n",
        "# For example, it might be '/content/drive/MyDrive/MyProjectCheckpoints/'\n",
        "\n",
        "# Ensure the Google Drive folder exists\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)\n",
        "    print(f\"Created Google Drive folder: {SAVE_PATH}\")\n",
        "\n",
        "# Generate a timestamp for the filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the new filename for the checkpoint\n",
        "new_checkpoint_filename = f\"model_{timestamp}_{NOTE}.pth\"\n",
        "destination_checkpoint_path = os.path.join(SAVE_PATH, new_checkpoint_filename)\n",
        "\n",
        "# Copy the checkpoint\n",
        "try:\n",
        "    shutil.copy(source_checkpoint_path, destination_checkpoint_path)\n",
        "    print(f\"Checkpoint successfully saved to: {destination_checkpoint_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Source checkpoint not found at {source_checkpoint_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the checkpoint: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mhJA7Kf7VB",
        "outputId": "b1cb9a09-54b8-4530-b377-c6220530f2ab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint successfully saved to: /content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/Artifacts/Checkpoints/model_20260110_151245_3dreg.pth\n"
          ]
        }
      ],
      "id": "p-mhJA7Kf7VB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reload the checkpoint (if needed)"
      ],
      "metadata": {
        "id": "fRJzvxFzhumr"
      },
      "id": "fRJzvxFzhumr"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# # Define the path to the checkpoint file\n",
        "destination_checkpoint_path = source_checkpoint_path #f'{GDRIVE_DIR}Artifacts/Checkpoints/model_20260107_081244_vanilla.pth'\n",
        "\n",
        "# Check if the checkpoint file exists\n",
        "if os.path.exists(destination_checkpoint_path):\n",
        "    # Load the checkpoint\n",
        "    loaded_checkpoint = torch.load(destination_checkpoint_path, map_location=torch.device('cpu')) # Use 'cuda' if you want to load to GPU\n",
        "    print(f\"Checkpoint loaded successfully from: {destination_checkpoint_path}\")\n",
        "    print(\"Keys in the loaded checkpoint:\", loaded_checkpoint.keys())\n",
        "\n",
        "    # Example of how you might load it into a model (assuming 'model' is defined)\n",
        "    # model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
        "    # epoch = loaded_checkpoint['epoch']\n",
        "    # loss = loaded_checkpoint['loss']\n",
        "else:\n",
        "    print(f\"Error: Checkpoint not found at {destination_checkpoint_path}\")\n"
      ],
      "metadata": {
        "id": "l3UZYdnshyZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42dd68f7-961f-44ca-cd61-02b2b84e8401"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded successfully from: /kaggle/temp/src/checkpoints_improved/best_model.pth\n",
            "Keys in the loaded checkpoint: odict_keys(['_orig_mod.smif.alpha', '_orig_mod.smif.conv_fuse.weight', '_orig_mod.smif.conv_fuse.bias', '_orig_mod.backbone.cls_token', '_orig_mod.backbone.pos_embed', '_orig_mod.backbone.patch_embed.proj.weight', '_orig_mod.backbone.patch_embed.proj.bias', '_orig_mod.backbone.blocks.0.norm1.weight', '_orig_mod.backbone.blocks.0.norm1.bias', '_orig_mod.backbone.blocks.0.attn.qkv.weight', '_orig_mod.backbone.blocks.0.attn.qkv.bias', '_orig_mod.backbone.blocks.0.attn.proj.weight', '_orig_mod.backbone.blocks.0.attn.proj.bias', '_orig_mod.backbone.blocks.0.norm2.weight', '_orig_mod.backbone.blocks.0.norm2.bias', '_orig_mod.backbone.blocks.0.mlp.fc1.weight', '_orig_mod.backbone.blocks.0.mlp.fc1.bias', '_orig_mod.backbone.blocks.0.mlp.fc2.weight', '_orig_mod.backbone.blocks.0.mlp.fc2.bias', '_orig_mod.backbone.blocks.0.lmim.delta', '_orig_mod.backbone.blocks.0.lmim.reduce.weight', '_orig_mod.backbone.blocks.0.lmim.reduce.bias', '_orig_mod.backbone.blocks.0.lmim.expand.weight', '_orig_mod.backbone.blocks.0.lmim.expand.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.1.norm1.weight', '_orig_mod.backbone.blocks.1.norm1.bias', '_orig_mod.backbone.blocks.1.attn.qkv.weight', '_orig_mod.backbone.blocks.1.attn.qkv.bias', '_orig_mod.backbone.blocks.1.attn.proj.weight', '_orig_mod.backbone.blocks.1.attn.proj.bias', '_orig_mod.backbone.blocks.1.norm2.weight', '_orig_mod.backbone.blocks.1.norm2.bias', '_orig_mod.backbone.blocks.1.mlp.fc1.weight', '_orig_mod.backbone.blocks.1.mlp.fc1.bias', '_orig_mod.backbone.blocks.1.mlp.fc2.weight', '_orig_mod.backbone.blocks.1.mlp.fc2.bias', '_orig_mod.backbone.blocks.1.lmim.delta', '_orig_mod.backbone.blocks.1.lmim.reduce.weight', '_orig_mod.backbone.blocks.1.lmim.reduce.bias', '_orig_mod.backbone.blocks.1.lmim.expand.weight', '_orig_mod.backbone.blocks.1.lmim.expand.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.2.norm1.weight', '_orig_mod.backbone.blocks.2.norm1.bias', '_orig_mod.backbone.blocks.2.attn.qkv.weight', '_orig_mod.backbone.blocks.2.attn.qkv.bias', '_orig_mod.backbone.blocks.2.attn.proj.weight', '_orig_mod.backbone.blocks.2.attn.proj.bias', '_orig_mod.backbone.blocks.2.norm2.weight', '_orig_mod.backbone.blocks.2.norm2.bias', '_orig_mod.backbone.blocks.2.mlp.fc1.weight', '_orig_mod.backbone.blocks.2.mlp.fc1.bias', '_orig_mod.backbone.blocks.2.mlp.fc2.weight', '_orig_mod.backbone.blocks.2.mlp.fc2.bias', '_orig_mod.backbone.blocks.2.lmim.delta', '_orig_mod.backbone.blocks.2.lmim.reduce.weight', '_orig_mod.backbone.blocks.2.lmim.reduce.bias', '_orig_mod.backbone.blocks.2.lmim.expand.weight', '_orig_mod.backbone.blocks.2.lmim.expand.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.3.norm1.weight', '_orig_mod.backbone.blocks.3.norm1.bias', '_orig_mod.backbone.blocks.3.attn.qkv.weight', '_orig_mod.backbone.blocks.3.attn.qkv.bias', '_orig_mod.backbone.blocks.3.attn.proj.weight', '_orig_mod.backbone.blocks.3.attn.proj.bias', '_orig_mod.backbone.blocks.3.norm2.weight', '_orig_mod.backbone.blocks.3.norm2.bias', '_orig_mod.backbone.blocks.3.mlp.fc1.weight', '_orig_mod.backbone.blocks.3.mlp.fc1.bias', '_orig_mod.backbone.blocks.3.mlp.fc2.weight', '_orig_mod.backbone.blocks.3.mlp.fc2.bias', '_orig_mod.backbone.blocks.3.lmim.delta', '_orig_mod.backbone.blocks.3.lmim.reduce.weight', '_orig_mod.backbone.blocks.3.lmim.reduce.bias', '_orig_mod.backbone.blocks.3.lmim.expand.weight', '_orig_mod.backbone.blocks.3.lmim.expand.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.4.norm1.weight', '_orig_mod.backbone.blocks.4.norm1.bias', '_orig_mod.backbone.blocks.4.attn.qkv.weight', '_orig_mod.backbone.blocks.4.attn.qkv.bias', '_orig_mod.backbone.blocks.4.attn.proj.weight', '_orig_mod.backbone.blocks.4.attn.proj.bias', '_orig_mod.backbone.blocks.4.norm2.weight', '_orig_mod.backbone.blocks.4.norm2.bias', '_orig_mod.backbone.blocks.4.mlp.fc1.weight', '_orig_mod.backbone.blocks.4.mlp.fc1.bias', '_orig_mod.backbone.blocks.4.mlp.fc2.weight', '_orig_mod.backbone.blocks.4.mlp.fc2.bias', '_orig_mod.backbone.blocks.4.lmim.delta', '_orig_mod.backbone.blocks.4.lmim.reduce.weight', '_orig_mod.backbone.blocks.4.lmim.reduce.bias', '_orig_mod.backbone.blocks.4.lmim.expand.weight', '_orig_mod.backbone.blocks.4.lmim.expand.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.5.norm1.weight', '_orig_mod.backbone.blocks.5.norm1.bias', '_orig_mod.backbone.blocks.5.attn.qkv.weight', '_orig_mod.backbone.blocks.5.attn.qkv.bias', '_orig_mod.backbone.blocks.5.attn.proj.weight', '_orig_mod.backbone.blocks.5.attn.proj.bias', '_orig_mod.backbone.blocks.5.norm2.weight', '_orig_mod.backbone.blocks.5.norm2.bias', '_orig_mod.backbone.blocks.5.mlp.fc1.weight', '_orig_mod.backbone.blocks.5.mlp.fc1.bias', '_orig_mod.backbone.blocks.5.mlp.fc2.weight', '_orig_mod.backbone.blocks.5.mlp.fc2.bias', '_orig_mod.backbone.blocks.5.lmim.delta', '_orig_mod.backbone.blocks.5.lmim.reduce.weight', '_orig_mod.backbone.blocks.5.lmim.reduce.bias', '_orig_mod.backbone.blocks.5.lmim.expand.weight', '_orig_mod.backbone.blocks.5.lmim.expand.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.6.norm1.weight', '_orig_mod.backbone.blocks.6.norm1.bias', '_orig_mod.backbone.blocks.6.attn.qkv.weight', '_orig_mod.backbone.blocks.6.attn.qkv.bias', '_orig_mod.backbone.blocks.6.attn.proj.weight', '_orig_mod.backbone.blocks.6.attn.proj.bias', '_orig_mod.backbone.blocks.6.norm2.weight', '_orig_mod.backbone.blocks.6.norm2.bias', '_orig_mod.backbone.blocks.6.mlp.fc1.weight', '_orig_mod.backbone.blocks.6.mlp.fc1.bias', '_orig_mod.backbone.blocks.6.mlp.fc2.weight', '_orig_mod.backbone.blocks.6.mlp.fc2.bias', '_orig_mod.backbone.blocks.6.lmim.delta', '_orig_mod.backbone.blocks.6.lmim.reduce.weight', '_orig_mod.backbone.blocks.6.lmim.reduce.bias', '_orig_mod.backbone.blocks.6.lmim.expand.weight', '_orig_mod.backbone.blocks.6.lmim.expand.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.7.norm1.weight', '_orig_mod.backbone.blocks.7.norm1.bias', '_orig_mod.backbone.blocks.7.attn.qkv.weight', '_orig_mod.backbone.blocks.7.attn.qkv.bias', '_orig_mod.backbone.blocks.7.attn.proj.weight', '_orig_mod.backbone.blocks.7.attn.proj.bias', '_orig_mod.backbone.blocks.7.norm2.weight', '_orig_mod.backbone.blocks.7.norm2.bias', '_orig_mod.backbone.blocks.7.mlp.fc1.weight', '_orig_mod.backbone.blocks.7.mlp.fc1.bias', '_orig_mod.backbone.blocks.7.mlp.fc2.weight', '_orig_mod.backbone.blocks.7.mlp.fc2.bias', '_orig_mod.backbone.blocks.7.lmim.delta', '_orig_mod.backbone.blocks.7.lmim.reduce.weight', '_orig_mod.backbone.blocks.7.lmim.reduce.bias', '_orig_mod.backbone.blocks.7.lmim.expand.weight', '_orig_mod.backbone.blocks.7.lmim.expand.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.8.norm1.weight', '_orig_mod.backbone.blocks.8.norm1.bias', '_orig_mod.backbone.blocks.8.attn.qkv.weight', '_orig_mod.backbone.blocks.8.attn.qkv.bias', '_orig_mod.backbone.blocks.8.attn.proj.weight', '_orig_mod.backbone.blocks.8.attn.proj.bias', '_orig_mod.backbone.blocks.8.norm2.weight', '_orig_mod.backbone.blocks.8.norm2.bias', '_orig_mod.backbone.blocks.8.mlp.fc1.weight', '_orig_mod.backbone.blocks.8.mlp.fc1.bias', '_orig_mod.backbone.blocks.8.mlp.fc2.weight', '_orig_mod.backbone.blocks.8.mlp.fc2.bias', '_orig_mod.backbone.blocks.8.lmim.delta', '_orig_mod.backbone.blocks.8.lmim.reduce.weight', '_orig_mod.backbone.blocks.8.lmim.reduce.bias', '_orig_mod.backbone.blocks.8.lmim.expand.weight', '_orig_mod.backbone.blocks.8.lmim.expand.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.9.norm1.weight', '_orig_mod.backbone.blocks.9.norm1.bias', '_orig_mod.backbone.blocks.9.attn.qkv.weight', '_orig_mod.backbone.blocks.9.attn.qkv.bias', '_orig_mod.backbone.blocks.9.attn.proj.weight', '_orig_mod.backbone.blocks.9.attn.proj.bias', '_orig_mod.backbone.blocks.9.norm2.weight', '_orig_mod.backbone.blocks.9.norm2.bias', '_orig_mod.backbone.blocks.9.mlp.fc1.weight', '_orig_mod.backbone.blocks.9.mlp.fc1.bias', '_orig_mod.backbone.blocks.9.mlp.fc2.weight', '_orig_mod.backbone.blocks.9.mlp.fc2.bias', '_orig_mod.backbone.blocks.9.lmim.delta', '_orig_mod.backbone.blocks.9.lmim.reduce.weight', '_orig_mod.backbone.blocks.9.lmim.reduce.bias', '_orig_mod.backbone.blocks.9.lmim.expand.weight', '_orig_mod.backbone.blocks.9.lmim.expand.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.10.norm1.weight', '_orig_mod.backbone.blocks.10.norm1.bias', '_orig_mod.backbone.blocks.10.attn.qkv.weight', '_orig_mod.backbone.blocks.10.attn.qkv.bias', '_orig_mod.backbone.blocks.10.attn.proj.weight', '_orig_mod.backbone.blocks.10.attn.proj.bias', '_orig_mod.backbone.blocks.10.norm2.weight', '_orig_mod.backbone.blocks.10.norm2.bias', '_orig_mod.backbone.blocks.10.mlp.fc1.weight', '_orig_mod.backbone.blocks.10.mlp.fc1.bias', '_orig_mod.backbone.blocks.10.mlp.fc2.weight', '_orig_mod.backbone.blocks.10.mlp.fc2.bias', '_orig_mod.backbone.blocks.10.lmim.delta', '_orig_mod.backbone.blocks.10.lmim.reduce.weight', '_orig_mod.backbone.blocks.10.lmim.reduce.bias', '_orig_mod.backbone.blocks.10.lmim.expand.weight', '_orig_mod.backbone.blocks.10.lmim.expand.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.11.norm1.weight', '_orig_mod.backbone.blocks.11.norm1.bias', '_orig_mod.backbone.blocks.11.attn.qkv.weight', '_orig_mod.backbone.blocks.11.attn.qkv.bias', '_orig_mod.backbone.blocks.11.attn.proj.weight', '_orig_mod.backbone.blocks.11.attn.proj.bias', '_orig_mod.backbone.blocks.11.norm2.weight', '_orig_mod.backbone.blocks.11.norm2.bias', '_orig_mod.backbone.blocks.11.mlp.fc1.weight', '_orig_mod.backbone.blocks.11.mlp.fc1.bias', '_orig_mod.backbone.blocks.11.mlp.fc2.weight', '_orig_mod.backbone.blocks.11.mlp.fc2.bias', '_orig_mod.backbone.blocks.11.lmim.delta', '_orig_mod.backbone.blocks.11.lmim.reduce.weight', '_orig_mod.backbone.blocks.11.lmim.reduce.bias', '_orig_mod.backbone.blocks.11.lmim.expand.weight', '_orig_mod.backbone.blocks.11.lmim.expand.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.norm.weight', '_orig_mod.backbone.norm.bias', '_orig_mod.head.weight', '_orig_mod.head.bias'])\n"
          ]
        }
      ],
      "id": "l3UZYdnshyZf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.001777,
          "end_time": "2026-01-06T03:35:23.475387",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.473610",
          "status": "completed"
        },
        "tags": [],
        "id": "mtDjbSeWIpHc"
      },
      "source": [
        "# Submission"
      ],
      "id": "mtDjbSeWIpHc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make submission file"
      ],
      "metadata": {
        "id": "sblI1-oItK2J"
      },
      "id": "sblI1-oItK2J"
    },
    {
      "cell_type": "code",
      "source": [
        "destination_checkpoint_path"
      ],
      "metadata": {
        "id": "MEuDfmGC8LiU",
        "outputId": "912371ec-0362-45e0-8c9d-b36339b91bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "MEuDfmGC8LiU",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/temp/src/checkpoints_improved/best_model.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "papermill": {
          "duration": 0.001736,
          "end_time": "2026-01-06T03:35:23.478842",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.477106",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a415598a-4835-464f-b107-1ca71f23f352",
        "id": "Fqun9L-mIpHd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "INFERENCE ON TEST SET\n",
            "Loading checkpoint from /kaggle/temp/src/checkpoints_improved/best_model.pth...\n",
            "Model loaded\n",
            "\n",
            "Loading test dataset...\n",
            "Test samples: 510\n",
            "\n",
            "Running inference...\n",
            "Processed 160/510 samples\n",
            "Processed 320/510 samples\n",
            "Processed 480/510 samples\n",
            "\n",
            "Inference complete! Processed 510 videos\n",
            "\n",
            "âœ“ Submission file created at: /kaggle/working/submission.csv\n",
            "\n",
            "Submission saved to: /kaggle/working/submission.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# !python inference.py --checkpoint {destination_checkpoint_path} \\\n",
        "#     --data_root {WORKING_DIR}data/test\n",
        "\n",
        "!export APPCONFIG__USE_3D_PATCH_EMBED=true\n",
        "!export APPCONFIG__TUBELET_SIZE=2\n",
        "\n",
        "!python inference.py \\\n",
        "  --checkpoint {destination_checkpoint_path} \\\n",
        "  --data_root {WORKING_DIR}data/test \\\n",
        "  --num_frames 16\n"
      ],
      "id": "Fqun9L-mIpHd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submit to Kaggle"
      ],
      "metadata": {
        "id": "uvrvFRHml6Uf"
      },
      "id": "uvrvFRHml6Uf"
    },
    {
      "cell_type": "code",
      "source": [
        "# !Must specify message\n",
        "MESSAGE = \"3d patch with regularization 3rd\""
      ],
      "metadata": {
        "id": "8Psuu70jmwBX"
      },
      "id": "8Psuu70jmwBX",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c action-video -f /kaggle/working/submission.csv -m \"{MESSAGE}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv0RLRt0jE6y",
        "outputId": "456442e6-e7f5-4546-9de5-7dda8f37b9d9"
      },
      "id": "bv0RLRt0jE6y",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 5.53k/5.53k [00:00<00:00, 9.54kB/s]\n",
            "Successfully submitted to AIO-2025: Video Action Classification Challenge"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p8NrDcSUlxrj"
      },
      "id": "p8NrDcSUlxrj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14910023,
          "sourceId": 125907,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31236,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4.587062,
      "end_time": "2026-01-06T03:35:23.698009",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2026-01-06T03:35:19.110947",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}