{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ef5c053",
      "metadata": {
        "papermill": {
          "duration": 0.002848,
          "end_time": "2026-01-06T03:35:21.884834",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.881986",
          "status": "completed"
        },
        "tags": [],
        "id": "3ef5c053"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Ic6JDbHAIXph"
      },
      "id": "Ic6JDbHAIXph",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f46f8cc",
      "metadata": {
        "papermill": {
          "duration": 0.00149,
          "end_time": "2026-01-06T03:35:21.887999",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.886509",
          "status": "completed"
        },
        "tags": [],
        "id": "4f46f8cc"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c2fc92c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.892327Z",
          "iopub.status.busy": "2026-01-06T03:35:21.891944Z",
          "iopub.status.idle": "2026-01-06T03:35:21.898008Z",
          "shell.execute_reply": "2026-01-06T03:35:21.897511Z"
        },
        "papermill": {
          "duration": 0.009684,
          "end_time": "2026-01-06T03:35:21.899305",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.889621",
          "status": "completed"
        },
        "tags": [],
        "id": "8c2fc92c"
      },
      "outputs": [],
      "source": [
        "WORKING_DIR = \"/kaggle/working/\"\n",
        "CODE_DIR = \"/kaggle/temp/src\"\n",
        "GDRIVE_DIR = \"/content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshm5WvXIdZB",
        "outputId": "f4bf99ef-c89b-4ef8-e1cd-cab127b8645c"
      },
      "id": "Jshm5WvXIdZB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "061a8517",
      "metadata": {
        "papermill": {
          "duration": 0.001467,
          "end_time": "2026-01-06T03:35:21.902523",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.901056",
          "status": "completed"
        },
        "tags": [],
        "id": "061a8517"
      },
      "source": [
        "## Download code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! Change branch name if not main\n",
        "BRANCH = \"ngocdung/model-improvement\""
      ],
      "metadata": {
        "id": "FFXhOBNLIv0Q"
      },
      "id": "FFXhOBNLIv0Q",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6deb560c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:21.906915Z",
          "iopub.status.busy": "2026-01-06T03:35:21.906454Z",
          "iopub.status.idle": "2026-01-06T03:35:22.809240Z",
          "shell.execute_reply": "2026-01-06T03:35:22.808363Z"
        },
        "papermill": {
          "duration": 0.906975,
          "end_time": "2026-01-06T03:35:22.811057",
          "exception": false,
          "start_time": "2026-01-06T03:35:21.904082",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6deb560c",
        "outputId": "4e9daf9f-4170-4a42-f265-e466afc78d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '/kaggle/temp/src'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 17 (delta 0), reused 8 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (17/17), 27.52 KiB | 2.29 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "# If directory \"src\" not exist then clone a new one\n",
        "!pwd\n",
        "![ -d \"{CODE_DIR}\" ] || git clone --depth 1  --branch \"{BRANCH}\" \"https://github.com/aio25-mix002/m07-p7.1\" \"{CODE_DIR}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1fdc6b4",
      "metadata": {
        "papermill": {
          "duration": 0.002046,
          "end_time": "2026-01-06T03:35:22.814997",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.812951",
          "status": "completed"
        },
        "tags": [],
        "id": "a1fdc6b4"
      },
      "source": [
        "## Fetch the latest code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "29c3a280",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-06T03:35:22.819938Z",
          "iopub.status.busy": "2026-01-06T03:35:22.819676Z",
          "iopub.status.idle": "2026-01-06T03:35:23.462681Z",
          "shell.execute_reply": "2026-01-06T03:35:23.461828Z"
        },
        "papermill": {
          "duration": 0.647535,
          "end_time": "2026-01-06T03:35:23.464347",
          "exception": false,
          "start_time": "2026-01-06T03:35:22.816812",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29c3a280",
        "outputId": "ced2ccba-6a28-4af5-c05a-0d3f8c1ffb8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/temp/src\n",
            "On branch ngocdung/model-improvement\n",
            "Your branch is up to date with 'origin/ngocdung/model-improvement'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "Already up to date.\n",
            "/kaggle/temp/src\n"
          ]
        }
      ],
      "source": [
        "# Go to CODE_DIR, Fetch the latest code\n",
        "%cd {CODE_DIR}\n",
        "!git clean -fdx\n",
        "!git status\n",
        "!git pull\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "g4QEb2HlZMiD"
      },
      "id": "g4QEb2HlZMiD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6315fe81"
      },
      "source": [
        "### Option 1: Using Kaggle API Credentials (Only if data in Google Drive not available)\n",
        "\n",
        "First, ensure you have downloaded your `kaggle.json` API token from your Kaggle account. Once downloaded, upload it to your Colab session. You can do this via the 'Files' tab on the left sidebar.\n",
        "\n",
        "After uploading, we will move it to the correct directory (`~/.kaggle/`) and set the necessary permissions."
      ],
      "id": "6315fe81"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "645da322",
        "outputId": "85db1bd1-583f-4c29-8549-a60662346c72"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create the .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move the uploaded kaggle.json file to the .kaggle directory\n",
        "# Assuming kaggle.json is in the current working directory after upload\n",
        "# If you uploaded it to a different path, please adjust '/content/kaggle.json'\n",
        "!mv /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Set permissions for the kaggle.json file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print('Kaggle API credentials set up successfully!')\n",
        "!ls -la ~/.kaggle/kaggle.json"
      ],
      "id": "645da322",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API credentials set up successfully!\n",
            "-rw------- 1 root root 67 Jan  9 12:46 /root/.kaggle/kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python download_data.py\n",
        "!kaggle competitions download -c action-video\n",
        "!unzip -q action-video.zip  -d {WORKING_DIR}"
      ],
      "metadata": {
        "id": "l6odimieZMIC",
        "outputId": "3ecae22b-b04c-4c97-97b0-486e5a2e6565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading action-video.zip to /kaggle/temp/src\n",
            " 95% 3.00G/3.14G [00:07<00:00, 171MB/s] \n",
            "100% 3.14G/3.14G [00:08<00:00, 420MB/s]\n"
          ]
        }
      ],
      "id": "l6odimieZMIC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Unused due to synchronizing problem) Option 2: Using data saved in Google Drive\n"
      ],
      "metadata": {
        "id": "lmes98ROmYtp"
      },
      "id": "lmes98ROmYtp"
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# source_gdrive_data_path = os.path.join(GDRIVE_DIR, 'Data')\n",
        "# destination_working_data_path = os.path.join(WORKING_DIR, 'data')\n",
        "\n",
        "# print(f\"Attempting to copy data from Google Drive: {source_gdrive_data_path}\")\n",
        "# print(f\"To working directory: {destination_working_data_path}\")\n",
        "\n",
        "# try:\n",
        "#     # Create the destination directory if it doesn't exist. If it exists, remove it first to avoid errors.\n",
        "#     if os.path.exists(destination_working_data_path):\n",
        "#         print(f\"Destination directory {destination_working_data_path} already exists. Removing before copy...\")\n",
        "#         shutil.rmtree(destination_working_data_path)\n",
        "\n",
        "#     shutil.copytree(source_gdrive_data_path, destination_working_data_path)\n",
        "#     print(f\"Successfully copied '{source_gdrive_data_path}' to '{destination_working_data_path}'\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Error: Source data directory not found in Google Drive at {source_gdrive_data_path}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"An error occurred while copying the data from Google Drive: {e}\")"
      ],
      "metadata": {
        "id": "duTIwNE6mYJ-"
      },
      "id": "duTIwNE6mYJ-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9a407c42",
      "metadata": {
        "papermill": {
          "duration": 0.001813,
          "end_time": "2026-01-06T03:35:23.468110",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.466297",
          "status": "completed"
        },
        "tags": [],
        "id": "9a407c42"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "CeiM2_IIk9wX"
      },
      "id": "CeiM2_IIk9wX"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "papermill": {
          "duration": 0.001816,
          "end_time": "2026-01-06T03:35:23.471692",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.469876",
          "status": "completed"
        },
        "tags": [],
        "outputId": "b44b38c4-bbb9-44a3-eae4-5827eac8b751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tt-BYnxIpHa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Initializing datasets...\n",
            "Train size: 5628 | Val size: 626\n",
            "Creating model...\n",
            "Downloading vit_base_patch16_224 weights via timm...\n",
            "model.safetensors: 100% 346M/346M [00:01<00:00, 306MB/s]\n",
            "Loaded pretrained weights. Missing: 132, Unexpected: 0\n",
            "ðŸš€ Compiling model with torch.compile...\n",
            "\n",
            "============================================================\n",
            "Training Configuration:\n",
            "  Epochs: 1\n",
            "  Batch size: 8\n",
            "  Learning rate: 0.0001\n",
            "  Num frames: 16\n",
            "  Frame stride: 2\n",
            "  Val ratio: 0.1\n",
            "  Checkpoint dir: ./checkpoints\n",
            "============================================================\n",
            "\n",
            "Backbone FROZEN (Chá»‰ train SMIF & Head)\n",
            "\n",
            "Epoch 1/1\n",
            "Train:   0% 0/704 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  return torch._C._get_cublas_allow_tf32()\n",
            "W0109 12:52:43.458000 2803 torch/_inductor/utils.py:1558] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "Val:   0% 0/79 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py:312: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
            "  warnings.warn(\n",
            "Train Loss: 3.4038 | Acc: 0.1633\n",
            "Val Loss: 3.3379   | Acc: 0.2093\n",
            "New best model saved! (0.2093)\n",
            "\n",
            "Training complete! Best validation accuracy: 0.2093\n"
          ]
        }
      ],
      "source": [
        "# Training - can change number of epochs\n",
        "# !python train.py #--epochs 1\n",
        "\n",
        "# Enable 3D patch embedding\n",
        "!export APPCONFIG__USE_3D_PATCH_EMBED=true\n",
        "\n",
        "# Set temporal patch size (tubelet size)\n",
        "!export APPCONFIG__TUBELET_SIZE=2  # Common values: 1, 2, 4\n",
        "\n",
        "# Spatial patch size (same as before)\n",
        "!export APPCONFIG__PATCH_SIZE=16\n",
        "\n",
        "# Set environment variable\n",
        "!export APPCONFIG__USE_3D_PATCH_EMBED=true\n",
        "!export APPCONFIG__TUBELET_SIZE=2\n",
        "\n",
        "# Run training\n",
        "!python train.py --num_frames 16 --epochs 1"
      ],
      "id": "6tt-BYnxIpHa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the best checkpoint to Google Drive"
      ],
      "metadata": {
        "id": "Ur0NsX_WhB8s"
      },
      "id": "Ur0NsX_WhB8s"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the brief note for the filename\n",
        "NOTE = \"3dtest\" # !!! Should edit every new run\n",
        "SAVE_PATH = f\"{GDRIVE_DIR}Artifacts/Checkpoints\"\n"
      ],
      "metadata": {
        "id": "u_Bun8y2hPnQ"
      },
      "execution_count": 12,
      "outputs": [],
      "id": "u_Bun8y2hPnQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the source path of the best model checkpoint\n",
        "source_checkpoint_path = os.path.join(CODE_DIR, 'checkpoints', 'best_model.pth')\n",
        "\n",
        "# Define your Google Drive destination folder path\n",
        "# IMPORTANT: Please replace 'YOUR_GOOGLE_DRIVE_FOLDER_PATH' with the actual path to your folder in Google Drive.\n",
        "# For example, it might be '/content/drive/MyDrive/MyProjectCheckpoints/'\n",
        "\n",
        "# Ensure the Google Drive folder exists\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)\n",
        "    print(f\"Created Google Drive folder: {SAVE_PATH}\")\n",
        "\n",
        "# Generate a timestamp for the filename\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Construct the new filename for the checkpoint\n",
        "new_checkpoint_filename = f\"model_{timestamp}_{NOTE}.pth\"\n",
        "destination_checkpoint_path = os.path.join(SAVE_PATH, new_checkpoint_filename)\n",
        "\n",
        "# Copy the checkpoint\n",
        "try:\n",
        "    shutil.copy(source_checkpoint_path, destination_checkpoint_path)\n",
        "    print(f\"Checkpoint successfully saved to: {destination_checkpoint_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Source checkpoint not found at {source_checkpoint_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while saving the checkpoint: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mhJA7Kf7VB",
        "outputId": "d495fb50-820a-4450-dba2-8a007320b22a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint successfully saved to: /content/drive/MyDrive/AIO25-MIX002/Projects/AIO2025_Conquer_CONQ008_M7_Project/Artifacts/Checkpoints/model_20260109_130654_3dtest.pth\n"
          ]
        }
      ],
      "id": "p-mhJA7Kf7VB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reload the checkpoint (if needed)"
      ],
      "metadata": {
        "id": "fRJzvxFzhumr"
      },
      "id": "fRJzvxFzhumr"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# # Define the path to the checkpoint file\n",
        "destination_checkpoint_path = source_checkpoint_path #f'{GDRIVE_DIR}Artifacts/Checkpoints/model_20260107_081244_vanilla.pth'\n",
        "\n",
        "# Check if the checkpoint file exists\n",
        "if os.path.exists(destination_checkpoint_path):\n",
        "    # Load the checkpoint\n",
        "    loaded_checkpoint = torch.load(destination_checkpoint_path, map_location=torch.device('cpu')) # Use 'cuda' if you want to load to GPU\n",
        "    print(f\"Checkpoint loaded successfully from: {destination_checkpoint_path}\")\n",
        "    print(\"Keys in the loaded checkpoint:\", loaded_checkpoint.keys())\n",
        "\n",
        "    # Example of how you might load it into a model (assuming 'model' is defined)\n",
        "    # model.load_state_dict(loaded_checkpoint['model_state_dict'])\n",
        "    # optimizer.load_state_dict(loaded_checkpoint['optimizer_state_dict'])\n",
        "    # epoch = loaded_checkpoint['epoch']\n",
        "    # loss = loaded_checkpoint['loss']\n",
        "else:\n",
        "    print(f\"Error: Checkpoint not found at {destination_checkpoint_path}\")\n"
      ],
      "metadata": {
        "id": "l3UZYdnshyZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412a9de5-f07e-4be1-e0e8-09749a1c020d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded successfully from: /kaggle/temp/src/checkpoints/best_model.pth\n",
            "Keys in the loaded checkpoint: odict_keys(['_orig_mod.smif.alpha', '_orig_mod.smif.conv_fuse.weight', '_orig_mod.smif.conv_fuse.bias', '_orig_mod.backbone.cls_token', '_orig_mod.backbone.pos_embed', '_orig_mod.backbone.patch_embed.proj.weight', '_orig_mod.backbone.patch_embed.proj.bias', '_orig_mod.backbone.blocks.0.norm1.weight', '_orig_mod.backbone.blocks.0.norm1.bias', '_orig_mod.backbone.blocks.0.attn.qkv.weight', '_orig_mod.backbone.blocks.0.attn.qkv.bias', '_orig_mod.backbone.blocks.0.attn.proj.weight', '_orig_mod.backbone.blocks.0.attn.proj.bias', '_orig_mod.backbone.blocks.0.norm2.weight', '_orig_mod.backbone.blocks.0.norm2.bias', '_orig_mod.backbone.blocks.0.mlp.fc1.weight', '_orig_mod.backbone.blocks.0.mlp.fc1.bias', '_orig_mod.backbone.blocks.0.mlp.fc2.weight', '_orig_mod.backbone.blocks.0.mlp.fc2.bias', '_orig_mod.backbone.blocks.0.lmim.delta', '_orig_mod.backbone.blocks.0.lmim.reduce.weight', '_orig_mod.backbone.blocks.0.lmim.reduce.bias', '_orig_mod.backbone.blocks.0.lmim.expand.weight', '_orig_mod.backbone.blocks.0.lmim.expand.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.0.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.1.norm1.weight', '_orig_mod.backbone.blocks.1.norm1.bias', '_orig_mod.backbone.blocks.1.attn.qkv.weight', '_orig_mod.backbone.blocks.1.attn.qkv.bias', '_orig_mod.backbone.blocks.1.attn.proj.weight', '_orig_mod.backbone.blocks.1.attn.proj.bias', '_orig_mod.backbone.blocks.1.norm2.weight', '_orig_mod.backbone.blocks.1.norm2.bias', '_orig_mod.backbone.blocks.1.mlp.fc1.weight', '_orig_mod.backbone.blocks.1.mlp.fc1.bias', '_orig_mod.backbone.blocks.1.mlp.fc2.weight', '_orig_mod.backbone.blocks.1.mlp.fc2.bias', '_orig_mod.backbone.blocks.1.lmim.delta', '_orig_mod.backbone.blocks.1.lmim.reduce.weight', '_orig_mod.backbone.blocks.1.lmim.reduce.bias', '_orig_mod.backbone.blocks.1.lmim.expand.weight', '_orig_mod.backbone.blocks.1.lmim.expand.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.1.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.2.norm1.weight', '_orig_mod.backbone.blocks.2.norm1.bias', '_orig_mod.backbone.blocks.2.attn.qkv.weight', '_orig_mod.backbone.blocks.2.attn.qkv.bias', '_orig_mod.backbone.blocks.2.attn.proj.weight', '_orig_mod.backbone.blocks.2.attn.proj.bias', '_orig_mod.backbone.blocks.2.norm2.weight', '_orig_mod.backbone.blocks.2.norm2.bias', '_orig_mod.backbone.blocks.2.mlp.fc1.weight', '_orig_mod.backbone.blocks.2.mlp.fc1.bias', '_orig_mod.backbone.blocks.2.mlp.fc2.weight', '_orig_mod.backbone.blocks.2.mlp.fc2.bias', '_orig_mod.backbone.blocks.2.lmim.delta', '_orig_mod.backbone.blocks.2.lmim.reduce.weight', '_orig_mod.backbone.blocks.2.lmim.reduce.bias', '_orig_mod.backbone.blocks.2.lmim.expand.weight', '_orig_mod.backbone.blocks.2.lmim.expand.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.2.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.3.norm1.weight', '_orig_mod.backbone.blocks.3.norm1.bias', '_orig_mod.backbone.blocks.3.attn.qkv.weight', '_orig_mod.backbone.blocks.3.attn.qkv.bias', '_orig_mod.backbone.blocks.3.attn.proj.weight', '_orig_mod.backbone.blocks.3.attn.proj.bias', '_orig_mod.backbone.blocks.3.norm2.weight', '_orig_mod.backbone.blocks.3.norm2.bias', '_orig_mod.backbone.blocks.3.mlp.fc1.weight', '_orig_mod.backbone.blocks.3.mlp.fc1.bias', '_orig_mod.backbone.blocks.3.mlp.fc2.weight', '_orig_mod.backbone.blocks.3.mlp.fc2.bias', '_orig_mod.backbone.blocks.3.lmim.delta', '_orig_mod.backbone.blocks.3.lmim.reduce.weight', '_orig_mod.backbone.blocks.3.lmim.reduce.bias', '_orig_mod.backbone.blocks.3.lmim.expand.weight', '_orig_mod.backbone.blocks.3.lmim.expand.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.3.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.4.norm1.weight', '_orig_mod.backbone.blocks.4.norm1.bias', '_orig_mod.backbone.blocks.4.attn.qkv.weight', '_orig_mod.backbone.blocks.4.attn.qkv.bias', '_orig_mod.backbone.blocks.4.attn.proj.weight', '_orig_mod.backbone.blocks.4.attn.proj.bias', '_orig_mod.backbone.blocks.4.norm2.weight', '_orig_mod.backbone.blocks.4.norm2.bias', '_orig_mod.backbone.blocks.4.mlp.fc1.weight', '_orig_mod.backbone.blocks.4.mlp.fc1.bias', '_orig_mod.backbone.blocks.4.mlp.fc2.weight', '_orig_mod.backbone.blocks.4.mlp.fc2.bias', '_orig_mod.backbone.blocks.4.lmim.delta', '_orig_mod.backbone.blocks.4.lmim.reduce.weight', '_orig_mod.backbone.blocks.4.lmim.reduce.bias', '_orig_mod.backbone.blocks.4.lmim.expand.weight', '_orig_mod.backbone.blocks.4.lmim.expand.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.4.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.5.norm1.weight', '_orig_mod.backbone.blocks.5.norm1.bias', '_orig_mod.backbone.blocks.5.attn.qkv.weight', '_orig_mod.backbone.blocks.5.attn.qkv.bias', '_orig_mod.backbone.blocks.5.attn.proj.weight', '_orig_mod.backbone.blocks.5.attn.proj.bias', '_orig_mod.backbone.blocks.5.norm2.weight', '_orig_mod.backbone.blocks.5.norm2.bias', '_orig_mod.backbone.blocks.5.mlp.fc1.weight', '_orig_mod.backbone.blocks.5.mlp.fc1.bias', '_orig_mod.backbone.blocks.5.mlp.fc2.weight', '_orig_mod.backbone.blocks.5.mlp.fc2.bias', '_orig_mod.backbone.blocks.5.lmim.delta', '_orig_mod.backbone.blocks.5.lmim.reduce.weight', '_orig_mod.backbone.blocks.5.lmim.reduce.bias', '_orig_mod.backbone.blocks.5.lmim.expand.weight', '_orig_mod.backbone.blocks.5.lmim.expand.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.5.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.6.norm1.weight', '_orig_mod.backbone.blocks.6.norm1.bias', '_orig_mod.backbone.blocks.6.attn.qkv.weight', '_orig_mod.backbone.blocks.6.attn.qkv.bias', '_orig_mod.backbone.blocks.6.attn.proj.weight', '_orig_mod.backbone.blocks.6.attn.proj.bias', '_orig_mod.backbone.blocks.6.norm2.weight', '_orig_mod.backbone.blocks.6.norm2.bias', '_orig_mod.backbone.blocks.6.mlp.fc1.weight', '_orig_mod.backbone.blocks.6.mlp.fc1.bias', '_orig_mod.backbone.blocks.6.mlp.fc2.weight', '_orig_mod.backbone.blocks.6.mlp.fc2.bias', '_orig_mod.backbone.blocks.6.lmim.delta', '_orig_mod.backbone.blocks.6.lmim.reduce.weight', '_orig_mod.backbone.blocks.6.lmim.reduce.bias', '_orig_mod.backbone.blocks.6.lmim.expand.weight', '_orig_mod.backbone.blocks.6.lmim.expand.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.6.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.7.norm1.weight', '_orig_mod.backbone.blocks.7.norm1.bias', '_orig_mod.backbone.blocks.7.attn.qkv.weight', '_orig_mod.backbone.blocks.7.attn.qkv.bias', '_orig_mod.backbone.blocks.7.attn.proj.weight', '_orig_mod.backbone.blocks.7.attn.proj.bias', '_orig_mod.backbone.blocks.7.norm2.weight', '_orig_mod.backbone.blocks.7.norm2.bias', '_orig_mod.backbone.blocks.7.mlp.fc1.weight', '_orig_mod.backbone.blocks.7.mlp.fc1.bias', '_orig_mod.backbone.blocks.7.mlp.fc2.weight', '_orig_mod.backbone.blocks.7.mlp.fc2.bias', '_orig_mod.backbone.blocks.7.lmim.delta', '_orig_mod.backbone.blocks.7.lmim.reduce.weight', '_orig_mod.backbone.blocks.7.lmim.reduce.bias', '_orig_mod.backbone.blocks.7.lmim.expand.weight', '_orig_mod.backbone.blocks.7.lmim.expand.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.7.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.8.norm1.weight', '_orig_mod.backbone.blocks.8.norm1.bias', '_orig_mod.backbone.blocks.8.attn.qkv.weight', '_orig_mod.backbone.blocks.8.attn.qkv.bias', '_orig_mod.backbone.blocks.8.attn.proj.weight', '_orig_mod.backbone.blocks.8.attn.proj.bias', '_orig_mod.backbone.blocks.8.norm2.weight', '_orig_mod.backbone.blocks.8.norm2.bias', '_orig_mod.backbone.blocks.8.mlp.fc1.weight', '_orig_mod.backbone.blocks.8.mlp.fc1.bias', '_orig_mod.backbone.blocks.8.mlp.fc2.weight', '_orig_mod.backbone.blocks.8.mlp.fc2.bias', '_orig_mod.backbone.blocks.8.lmim.delta', '_orig_mod.backbone.blocks.8.lmim.reduce.weight', '_orig_mod.backbone.blocks.8.lmim.reduce.bias', '_orig_mod.backbone.blocks.8.lmim.expand.weight', '_orig_mod.backbone.blocks.8.lmim.expand.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.8.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.9.norm1.weight', '_orig_mod.backbone.blocks.9.norm1.bias', '_orig_mod.backbone.blocks.9.attn.qkv.weight', '_orig_mod.backbone.blocks.9.attn.qkv.bias', '_orig_mod.backbone.blocks.9.attn.proj.weight', '_orig_mod.backbone.blocks.9.attn.proj.bias', '_orig_mod.backbone.blocks.9.norm2.weight', '_orig_mod.backbone.blocks.9.norm2.bias', '_orig_mod.backbone.blocks.9.mlp.fc1.weight', '_orig_mod.backbone.blocks.9.mlp.fc1.bias', '_orig_mod.backbone.blocks.9.mlp.fc2.weight', '_orig_mod.backbone.blocks.9.mlp.fc2.bias', '_orig_mod.backbone.blocks.9.lmim.delta', '_orig_mod.backbone.blocks.9.lmim.reduce.weight', '_orig_mod.backbone.blocks.9.lmim.reduce.bias', '_orig_mod.backbone.blocks.9.lmim.expand.weight', '_orig_mod.backbone.blocks.9.lmim.expand.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.9.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.10.norm1.weight', '_orig_mod.backbone.blocks.10.norm1.bias', '_orig_mod.backbone.blocks.10.attn.qkv.weight', '_orig_mod.backbone.blocks.10.attn.qkv.bias', '_orig_mod.backbone.blocks.10.attn.proj.weight', '_orig_mod.backbone.blocks.10.attn.proj.bias', '_orig_mod.backbone.blocks.10.norm2.weight', '_orig_mod.backbone.blocks.10.norm2.bias', '_orig_mod.backbone.blocks.10.mlp.fc1.weight', '_orig_mod.backbone.blocks.10.mlp.fc1.bias', '_orig_mod.backbone.blocks.10.mlp.fc2.weight', '_orig_mod.backbone.blocks.10.mlp.fc2.bias', '_orig_mod.backbone.blocks.10.lmim.delta', '_orig_mod.backbone.blocks.10.lmim.reduce.weight', '_orig_mod.backbone.blocks.10.lmim.reduce.bias', '_orig_mod.backbone.blocks.10.lmim.expand.weight', '_orig_mod.backbone.blocks.10.lmim.expand.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.10.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.blocks.11.norm1.weight', '_orig_mod.backbone.blocks.11.norm1.bias', '_orig_mod.backbone.blocks.11.attn.qkv.weight', '_orig_mod.backbone.blocks.11.attn.qkv.bias', '_orig_mod.backbone.blocks.11.attn.proj.weight', '_orig_mod.backbone.blocks.11.attn.proj.bias', '_orig_mod.backbone.blocks.11.norm2.weight', '_orig_mod.backbone.blocks.11.norm2.bias', '_orig_mod.backbone.blocks.11.mlp.fc1.weight', '_orig_mod.backbone.blocks.11.mlp.fc1.bias', '_orig_mod.backbone.blocks.11.mlp.fc2.weight', '_orig_mod.backbone.blocks.11.mlp.fc2.bias', '_orig_mod.backbone.blocks.11.lmim.delta', '_orig_mod.backbone.blocks.11.lmim.reduce.weight', '_orig_mod.backbone.blocks.11.lmim.reduce.bias', '_orig_mod.backbone.blocks.11.lmim.expand.weight', '_orig_mod.backbone.blocks.11.lmim.expand.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.0.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.0.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.1.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.1.bias', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.3.weight', '_orig_mod.backbone.blocks.11.lmim.temporal_mlp.3.bias', '_orig_mod.backbone.norm.weight', '_orig_mod.backbone.norm.bias', '_orig_mod.head.weight', '_orig_mod.head.bias'])\n"
          ]
        }
      ],
      "id": "l3UZYdnshyZf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.001777,
          "end_time": "2026-01-06T03:35:23.475387",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.473610",
          "status": "completed"
        },
        "tags": [],
        "id": "mtDjbSeWIpHc"
      },
      "source": [
        "# Submission"
      ],
      "id": "mtDjbSeWIpHc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make submission file"
      ],
      "metadata": {
        "id": "sblI1-oItK2J"
      },
      "id": "sblI1-oItK2J"
    },
    {
      "cell_type": "code",
      "source": [
        "destination_checkpoint_path"
      ],
      "metadata": {
        "id": "MEuDfmGC8LiU",
        "outputId": "7ffdbf4a-4bf1-4799-909f-31210ad05587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "MEuDfmGC8LiU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/kaggle/temp/src/checkpoints/best_model.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "papermill": {
          "duration": 0.001736,
          "end_time": "2026-01-06T03:35:23.478842",
          "exception": false,
          "start_time": "2026-01-06T03:35:23.477106",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b742296-0b2f-4a9f-8077-0f2e8c3c6943",
        "id": "Fqun9L-mIpHd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "INFERENCE ON TEST SET\n",
            "Loading checkpoint from /kaggle/temp/src/checkpoints/best_model.pth...\n",
            "Model loaded\n",
            "\n",
            "Loading test dataset...\n",
            "Test samples: 510\n",
            "\n",
            "Running inference...\n",
            "Processed 160/510 samples\n",
            "Processed 320/510 samples\n",
            "Processed 480/510 samples\n",
            "\n",
            "Inference complete! Processed 510 videos\n",
            "\n",
            "âœ“ Submission file created at: /kaggle/working/submission.csv\n",
            "\n",
            "Submission saved to: /kaggle/working/submission.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# !python inference.py --checkpoint {destination_checkpoint_path} \\\n",
        "#     --data_root {WORKING_DIR}data/test\n",
        "\n",
        "!export APPCONFIG__USE_3D_PATCH_EMBED=true\n",
        "!export APPCONFIG__TUBELET_SIZE=2\n",
        "\n",
        "!python inference.py \\\n",
        "  --checkpoint {destination_checkpoint_path} \\\n",
        "  --data_root {WORKING_DIR}data/test \\\n",
        "  --num_frames 16\n"
      ],
      "id": "Fqun9L-mIpHd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submit to Kaggle"
      ],
      "metadata": {
        "id": "uvrvFRHml6Uf"
      },
      "id": "uvrvFRHml6Uf"
    },
    {
      "cell_type": "code",
      "source": [
        "# !Must specify message\n",
        "MESSAGE = \"Testing runbook.ipynb 3rd time\""
      ],
      "metadata": {
        "id": "8Psuu70jmwBX"
      },
      "id": "8Psuu70jmwBX",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c action-video -f /kaggle/working/submission.csv -m \"{MESSAGE}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv0RLRt0jE6y",
        "outputId": "26edd598-caab-4c36-b27f-e52ef96d1e4f"
      },
      "id": "bv0RLRt0jE6y",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 3.23k/3.23k [00:00<00:00, 5.73kB/s]\n",
            "Successfully submitted to AIO-2025: Video Action Classification Challenge"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p8NrDcSUlxrj"
      },
      "id": "p8NrDcSUlxrj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 14910023,
          "sourceId": 125907,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31236,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4.587062,
      "end_time": "2026-01-06T03:35:23.698009",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2026-01-06T03:35:19.110947",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}