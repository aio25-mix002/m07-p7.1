{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944799da-70c2-439c-b9ec-a8d4f27823f9",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aio25-mix002/m07-p7.1/blob/main/notebooks/runbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5c053",
   "metadata": {
    "id": "3ef5c053",
    "papermill": {
     "duration": 0.002848,
     "end_time": "2026-01-06T03:35:21.884834",
     "exception": false,
     "start_time": "2026-01-06T03:35:21.881986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60996d26-e5a1-4a7e-80b9-6e00d69fb0bc",
   "metadata": {},
   "source": [
    "## Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c21c26b4-58bf-4ec9-9b54-38e6bef1b23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:02.604787Z",
     "iopub.status.busy": "2026-01-08T16:15:02.604412Z",
     "iopub.status.idle": "2026-01-08T16:15:02.611607Z",
     "shell.execute_reply": "2026-01-08T16:15:02.611006Z",
     "shell.execute_reply.started": "2026-01-08T16:15:02.604735Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: kaggle\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def notebook_runtime() -> str:\n",
    "    # Kaggle\n",
    "    if any(k in os.environ for k in (\"KAGGLE_URL_BASE\", \"KAGGLE_KERNEL_RUN_TYPE\", \"KAGGLE_DATA_PROXY_TOKEN\")) \\\n",
    "       or Path(\"/kaggle\").exists():\n",
    "        return \"kaggle\"\n",
    "\n",
    "    # Google Colab\n",
    "    if \"COLAB_RELEASE_TAG\" in os.environ or \"COLAB_GPU\" in os.environ or Path(\"/content\").exists():\n",
    "        return \"colab\"\n",
    "\n",
    "    # Local / other Jupyter (VS Code, JupyterLab, etc.)\n",
    "    return \"local\"\n",
    "\n",
    "NOTEBOOK_RUNTIME = notebook_runtime()\n",
    "print(\"Runtime:\", NOTEBOOK_RUNTIME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f46f8cc",
   "metadata": {
    "id": "4f46f8cc",
    "papermill": {
     "duration": 0.00149,
     "end_time": "2026-01-06T03:35:21.887999",
     "exception": false,
     "start_time": "2026-01-06T03:35:21.886509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c2fc92c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:02.612930Z",
     "iopub.status.busy": "2026-01-08T16:15:02.612688Z",
     "iopub.status.idle": "2026-01-08T16:15:02.625648Z",
     "shell.execute_reply": "2026-01-08T16:15:02.625127Z",
     "shell.execute_reply.started": "2026-01-08T16:15:02.612909Z"
    },
    "id": "8c2fc92c",
    "papermill": {
     "duration": 0.009684,
     "end_time": "2026-01-06T03:35:21.899305",
     "exception": false,
     "start_time": "2026-01-06T03:35:21.889621",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] Configuring kaggle\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "SAVE_TO_REMOTE_STORAGE = True\n",
    "ROOT_DIR = None\n",
    "WORKING_DIR = None\n",
    "CODE_DIR = None\n",
    "INPUT_DATA_DIR = None\n",
    "OUTPUT_DIR = None\n",
    "APPCONFIG_ENV_FILENAME = None\n",
    "\n",
    "if NOTEBOOK_RUNTIME == \"kaggle\":\n",
    "    SAVE_TO_REMOTE_STORAGE = False\n",
    "    ROOT_DIR = Path(\"/kaggle/\")\n",
    "    WORKING_DIR = ROOT_DIR / \"working/\"\n",
    "    CODE_DIR = ROOT_DIR / \"temp/src\"\n",
    "    INPUT_DATA_DIR = ROOT_DIR / \"input/action-video/data\"\n",
    "    APPCONFIG_ENV_FILENAME = \".env.kaggle\"\n",
    "\n",
    "\n",
    "elif NOTEBOOK_RUNTIME == \"colab\":\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    SAVE_TO_REMOTE_STORAGE = True\n",
    "\n",
    "else:\n",
    "    SAVE_TO_REMOTE_STORAGE = False\n",
    "    \n",
    "    # Init root dir once as the working dir can be changed after than. \n",
    "    if ROOT_DIR is None:\n",
    "        ROOT_DIR = (Path.cwd().parent).absolute()\n",
    "    WORKING_DIR = ROOT_DIR / \"kaggle/working/\"\n",
    "    CODE_DIR = ROOT_DIR\n",
    "    INPUT_DATA_DIR = ROOT_DIR / \"kaggle/competitions/action-video/data\"\n",
    "    APPCONFIG_ENV_FILENAME = \".env.local\"\n",
    "        \n",
    "    \n",
    "\n",
    "print(f\"[Done] Configuring {NOTEBOOK_RUNTIME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c806ab7-936f-4916-9ee0-f6a7c421fc50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:02.626642Z",
     "iopub.status.busy": "2026-01-08T16:15:02.626414Z",
     "iopub.status.idle": "2026-01-08T16:15:02.646961Z",
     "shell.execute_reply": "2026-01-08T16:15:02.646312Z",
     "shell.execute_reply.started": "2026-01-08T16:15:02.626610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /kaggle/working\n",
      "checkpoints\n",
      ".virtual_documents\n",
      "Input Data Directory: /kaggle/input/action-video/data\n",
      "data_train\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"Working Directory:\", WORKING_DIR)\n",
    "for item in os.listdir(WORKING_DIR):\n",
    "    print(f\"{item}\")\n",
    "    \n",
    "print(\"Input Data Directory:\", INPUT_DATA_DIR)\n",
    "for item in os.listdir(INPUT_DATA_DIR):\n",
    "    print(f\"{item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6446dd-09f9-4294-b753-1e1cb0927b99",
   "metadata": {},
   "source": [
    "## Connect to a shared storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a8517",
   "metadata": {
    "id": "061a8517",
    "papermill": {
     "duration": 0.001467,
     "end_time": "2026-01-06T03:35:21.902523",
     "exception": false,
     "start_time": "2026-01-06T03:35:21.901056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Download code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6deb560c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:02.648443Z",
     "iopub.status.busy": "2026-01-08T16:15:02.648193Z",
     "iopub.status.idle": "2026-01-08T16:15:02.944931Z",
     "shell.execute_reply": "2026-01-08T16:15:02.943976Z",
     "shell.execute_reply.started": "2026-01-08T16:15:02.648425Z"
    },
    "id": "6deb560c",
    "outputId": "cfb89a3d-df66-4bd2-b102-e6b5348d22f9",
    "papermill": {
     "duration": 0.906975,
     "end_time": "2026-01-06T03:35:22.811057",
     "exception": false,
     "start_time": "2026-01-06T03:35:21.904082",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/temp/src\n"
     ]
    }
   ],
   "source": [
    "# If directory \"src\" not exist then clone a new one\n",
    "!pwd\n",
    "![ -d \"{CODE_DIR}\" ] || git clone --depth 1  --branch \"users/hung-doan/000-update-notebook-log\" \"https://github.com/aio25-mix002/m07-p7.1\" \"{CODE_DIR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fdc6b4",
   "metadata": {
    "id": "a1fdc6b4",
    "papermill": {
     "duration": 0.002046,
     "end_time": "2026-01-06T03:35:22.814997",
     "exception": false,
     "start_time": "2026-01-06T03:35:22.812951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fetch the latest code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29c3a280",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:02.947215Z",
     "iopub.status.busy": "2026-01-08T16:15:02.946888Z",
     "iopub.status.idle": "2026-01-08T16:15:03.903251Z",
     "shell.execute_reply": "2026-01-08T16:15:03.902378Z",
     "shell.execute_reply.started": "2026-01-08T16:15:02.947187Z"
    },
    "id": "29c3a280",
    "outputId": "419bda26-548c-4009-d7ec-da439f5af5e5",
    "papermill": {
     "duration": 0.647535,
     "end_time": "2026-01-06T03:35:23.464347",
     "exception": false,
     "start_time": "2026-01-06T03:35:22.816812",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/temp/src\n",
      "Removing build/\n",
      "Removing logs/\n",
      "Removing src/__pycache__/\n",
      "Removing src/lsvit_hmdb51.egg-info/\n",
      "On branch users/hung-doan/000-update-notebook-log\n",
      "Your branch is up to date with 'origin/users/hung-doan/000-update-notebook-log'.\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 6 (delta 5), reused 6 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (6/6), 779 bytes | 389.00 KiB/s, done.\n",
      "From https://github.com/aio25-mix002/m07-p7.1\n",
      "   6138edf..a223acf  users/hung-doan/000-update-notebook-log -> origin/users/hung-doan/000-update-notebook-log\n",
      "Updating 6138edf..a223acf\n",
      "Fast-forward\n",
      " .env.kaggle  |  3 \u001b[32m++\u001b[m\u001b[31m-\u001b[m\n",
      " src/utils.py | 10 \u001b[32m+++++++++\u001b[m\u001b[31m-\u001b[m\n",
      " train.py     | 39 \u001b[32m+++++++++++++++\u001b[m\u001b[31m------------------------\u001b[m\n",
      " 3 files changed, 26 insertions(+), 26 deletions(-)\n",
      "/kaggle/temp/src\n"
     ]
    }
   ],
   "source": [
    "# Go to CODE_DIR, Fetch the latest code\n",
    "%cd {CODE_DIR}\n",
    "!git clean -fdx\n",
    "!git status\n",
    "!git pull\n",
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g4QEb2HlZMiD",
   "metadata": {
    "id": "g4QEb2HlZMiD"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "l6odimieZMIC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:03.904907Z",
     "iopub.status.busy": "2026-01-08T16:15:03.904574Z",
     "iopub.status.idle": "2026-01-08T16:15:03.909197Z",
     "shell.execute_reply": "2026-01-08T16:15:03.908483Z",
     "shell.execute_reply.started": "2026-01-08T16:15:03.904871Z"
    },
    "id": "l6odimieZMIC",
    "outputId": "074041c5-a2fe-4522-a63a-99ccda440c8b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "if NOTEBOOK_RUNTIME != \"kaggle\":\n",
    "    # run the script with the same Python interpreter as the notebook\n",
    "    subprocess.check_call([sys.executable, f\"{CODE_DIR}/download_data.py\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a407c42",
   "metadata": {
    "id": "9a407c42",
    "papermill": {
     "duration": 0.001813,
     "end_time": "2026-01-06T03:35:23.468110",
     "exception": false,
     "start_time": "2026-01-06T03:35:23.466297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76f5d8f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:03.911634Z",
     "iopub.status.busy": "2026-01-08T16:15:03.911024Z",
     "iopub.status.idle": "2026-01-08T16:15:03.926848Z",
     "shell.execute_reply": "2026-01-08T16:15:03.925939Z",
     "shell.execute_reply.started": "2026-01-08T16:15:03.911610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.chdir(CODE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee775996-e296-463a-8d29-bca3473868a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:03.927946Z",
     "iopub.status.busy": "2026-01-08T16:15:03.927686Z",
     "iopub.status.idle": "2026-01-08T16:15:48.976133Z",
     "shell.execute_reply": "2026-01-08T16:15:48.975039Z",
     "shell.execute_reply.started": "2026-01-08T16:15:03.927914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython 3.12.12 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "\u001b[2mResolved \u001b[1m161 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m91 packages\u001b[0m \u001b[2min 44.16s\u001b[0m\u001b[0m                                           \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m91 packages\u001b[0m \u001b[2min 448ms\u001b[0m\u001b[0m                              \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2026.1.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.19\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.61.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgdown\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhf-xet\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipywidgets\u001b[0m\u001b[2m==8.1.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjupyterlab-widgets\u001b[0m\u001b[2m==3.0.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkagglehub\u001b[0m\u001b[2m==0.3.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.52\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpysocks\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mruff\u001b[0m\u001b[2m==0.14.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtimm\u001b[0m\u001b[2m==1.0.24\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.21.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwidgetsnbextension\u001b[0m\u001b[2m==4.0.15\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d008814b-a863-4e6d-bf31-8aaae8f9d40b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:48.978615Z",
     "iopub.status.busy": "2026-01-08T16:15:48.977482Z",
     "iopub.status.idle": "2026-01-08T16:15:48.985779Z",
     "shell.execute_reply": "2026-01-08T16:15:48.985089Z",
     "shell.execute_reply.started": "2026-01-08T16:15:48.978580Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the environment variables\n"
     ]
    }
   ],
   "source": [
    "if not load_dotenv(dotenv_path= CODE_DIR / f\"./{APPCONFIG_ENV_FILENAME}\"):\n",
    "    print(f\"Warning: No {APPCONFIG_ENV_FILENAME} file found in {CODE_DIR}\")\n",
    "else:\n",
    "    print(\"Loaded the environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42514f25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-01-08T16:15:48.986871Z",
     "iopub.status.busy": "2026-01-08T16:15:48.986596Z",
     "iopub.status.idle": "2026-01-08T17:01:47.914854Z",
     "shell.execute_reply": "2026-01-08T17:01:47.913946Z",
     "shell.execute_reply.started": "2026-01-08T16:15:48.986845Z"
    },
    "id": "42514f25",
    "outputId": "68e97d76-5da1-4cab-dfe6-571afad0ed5c",
    "papermill": {
     "duration": 0.001816,
     "end_time": "2026-01-06T03:35:23.471692",
     "exception": false,
     "start_time": "2026-01-06T03:35:23.469876",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "\u001b[32m2026-01-08 16:15:58.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mEXPR NAME: default_expr\u001b[0m\n",
      "\u001b[32m2026-01-08 16:15:58.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mUsing device: cuda\u001b[0m\n",
      "\u001b[32m2026-01-08 16:15:58.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mInitializing datasets...\u001b[0m\n",
      "\u001b[32m2026-01-08 16:16:13.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mTrain size: 5628 | Val size: 626\u001b[0m\n",
      "\u001b[32m2026-01-08 16:16:13.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mCreating model...\u001b[0m\n",
      "Loaded pretrained weights. Missing: 132, Unexpected: 0\n",
      "\u001b[32m2026-01-08 16:16:14.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mðŸ”¥ KÃ­ch hoáº¡t cháº¿ Ä‘á»™ Multi-GPU trÃªn 2 card!\u001b[0m\n",
      "\u001b[32m2026-01-08 16:16:14.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mðŸš€ Compiling model with torch.compile...\u001b[0m\n",
      "\u001b[32m2026-01-08 16:16:16.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mBackbone FROZEN (Chá»‰ train SMIF & Head)\u001b[0m\n",
      "\u001b[32m2026-01-08 16:16:16.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m\n",
      "Epoch 1/10\u001b[0m\n",
      "Train:   0%|                                            | 0/704 [00:00<?, ?it/s]W0108 16:16:19.263000 4463 torch/_logging/_internal.py:1154] [0/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n",
      "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1481: UserWarning: Dynamo does not know how to trace the builtin `_thread.get_ident.` This function is either a Python builtin (e.g. _warnings.warn) or a third-party C/C++ Python extension (perhaps created with pybind).\n",
      "If it is a Python builtin, please file an issue on GitHub so the PyTorch team can add support for it and see the next case for a workaround.\n",
      "If it is a third-party C/C++ Python extension, please either wrap it into a PyTorch-understood custom operator (see https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html for more details) or, if it is traceable, use `torch.compiler.allow_in_graph`.\n",
      "  torch._dynamo.utils.warn_once(explanation + \"\\n\" + \"\\n\".join(hints))\n",
      "Train:   1%|           | 4/704 [00:11<23:31,  2.02s/it, acc=0.0000, loss=4.0725]W0108 16:16:28.371000 4463 torch/_dynamo/convert_frame.py:1016] [3/8] torch._dynamo hit config.recompile_limit (8)\n",
      "W0108 16:16:28.371000 4463 torch/_dynamo/convert_frame.py:1016] [3/8]    function: 'torch_dynamo_resume_in___init___at_913' (/usr/lib/python3.12/threading.py:913)\n",
      "W0108 16:16:28.371000 4463 torch/_dynamo/convert_frame.py:1016] [3/8]    last reason: 3/7: ___stack0 == 'Thread-11'                               \n",
      "W0108 16:16:28.371000 4463 torch/_dynamo/convert_frame.py:1016] [3/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W0108 16:16:28.371000 4463 torch/_dynamo/convert_frame.py:1016] [3/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "\u001b[32m2026-01-08 16:27:51.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mTrain Loss: 3.4141 | Acc: 0.1537\u001b[0m\n",
      "\u001b[32m2026-01-08 16:27:51.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mVal Loss: 3.3476   | Acc: 0.2013\u001b[0m\n",
      "Checkpoint saved to /kaggle/working/checkpoints/20260108_162751_default_expr\n",
      "\u001b[32m2026-01-08 16:27:52.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mNew best model saved! (0.2013)\u001b[0m\n",
      "\u001b[32m2026-01-08 16:27:52.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mBackbone FROZEN (Chá»‰ train SMIF & Head)\u001b[0m\n",
      "\u001b[32m2026-01-08 16:27:52.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m\n",
      "Epoch 2/10\u001b[0m\n",
      "\u001b[32m2026-01-08 16:39:14.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mTrain Loss: 2.7667 | Acc: 0.3216\u001b[0m\n",
      "\u001b[32m2026-01-08 16:39:14.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mVal Loss: 2.9755   | Acc: 0.2827\u001b[0m\n",
      "Checkpoint saved to /kaggle/working/checkpoints/20260108_163914_default_expr\n",
      "\u001b[32m2026-01-08 16:39:14.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mNew best model saved! (0.2827)\u001b[0m\n",
      "\u001b[32m2026-01-08 16:39:14.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mBackbone FROZEN (Chá»‰ train SMIF & Head)\u001b[0m\n",
      "\u001b[32m2026-01-08 16:39:14.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m\n",
      "Epoch 3/10\u001b[0m\n",
      "\u001b[32m2026-01-08 16:50:37.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mTrain Loss: 2.4446 | Acc: 0.3980\u001b[0m\n",
      "\u001b[32m2026-01-08 16:50:37.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mVal Loss: 2.8156   | Acc: 0.3131\u001b[0m\n",
      "Checkpoint saved to /kaggle/working/checkpoints/20260108_165037_default_expr\n",
      "\u001b[32m2026-01-08 16:50:37.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mNew best model saved! (0.3131)\u001b[0m\n",
      "\u001b[32m2026-01-08 16:50:37.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mBackbone UN-FROZEN (Train toÃ n bá»™)\u001b[0m\n",
      "\u001b[32m2026-01-08 16:50:37.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.logging_utils\u001b[0m:\u001b[36minfo\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1m\n",
      "Epoch 4/10\u001b[0m\n",
      "Train:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 643/704 [11:08<01:02,  1.03s/it, acc=0.2597, loss=1.9221]^C\n",
      "Traceback (most recent call last):                                              \n",
      "  File \"/kaggle/temp/src/./train.py\", line 159, in <module>\n",
      "    main()\n",
      "  File \"/kaggle/temp/src/./train.py\", line 118, in main\n",
      "    train_loss, train_acc = train_one_epoch(\n",
      "                            ^^^^^^^^^^^^^^^^\n",
      "  File \"/kaggle/temp/src/src/engine.py\", line 39, in train_one_epoch\n",
      "    scaler.step(optimizer)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 465, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 359, in _maybe_opt_step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 359, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "               ^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -u ./train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zk6Ch9-Jf0fs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2026-01-08T17:01:51.795358Z",
     "iopub.status.idle": "2026-01-08T17:01:51.795615Z",
     "shell.execute_reply": "2026-01-08T17:01:51.795516Z",
     "shell.execute_reply.started": "2026-01-08T17:01:51.795498Z"
    },
    "id": "zk6Ch9-Jf0fs",
    "outputId": "3d6235bf-2e56-467a-a23c-c5686fd9d5d3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from src.config import ModelConfig, TrainingConfig\n",
    "from src.utils import find_latest_checkpoint\n",
    "\n",
    "t_cfg = TrainingConfig()\n",
    "train_saved_chk_dir: str = find_latest_checkpoint(t_cfg.checkpoint_dir, t_cfg.expr_name)\n",
    "print(\"Latest Checkpoint Location:\", train_saved_chk_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d11777",
   "metadata": {
    "id": "39d11777",
    "papermill": {
     "duration": 0.001777,
     "end_time": "2026-01-06T03:35:23.475387",
     "exception": false,
     "start_time": "2026-01-06T03:35:23.473610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca285f6d-1c12-4c4f-b34f-93d6b69bc742",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e396697a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "execution": {
     "iopub.execute_input": "2026-01-08T17:06:15.002504Z",
     "iopub.status.busy": "2026-01-08T17:06:15.001512Z",
     "iopub.status.idle": "2026-01-08T17:06:16.228678Z",
     "shell.execute_reply": "2026-01-08T17:06:16.227944Z",
     "shell.execute_reply.started": "2026-01-08T17:06:15.002455Z"
    },
    "id": "e396697a",
    "outputId": "62ffcdb0-2431-4a92-95ce-273aaa07bd84",
    "papermill": {
     "duration": 0.001736,
     "end_time": "2026-01-06T03:35:23.478842",
     "exception": false,
     "start_time": "2026-01-06T03:35:23.477106",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: trained acc: 0.3131; 51 classes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.model import LSViTForAction\n",
    "\n",
    "# Config\n",
    "m_cfg = ModelConfig()\n",
    "inf_model = LSViTForAction(config=m_cfg)\n",
    "\n",
    "# Load the model checkpoint\n",
    "checkpoint = torch.load(\n",
    "    os.path.join(train_saved_chk_dir, \"best_model.pth\"), map_location=t_cfg.device\n",
    ")\n",
    "inf_model.load_state_dict(checkpoint['model'])\n",
    "inf_model = inf_model.to(t_cfg.device)  # Move model to device\n",
    "inf_model.eval()\n",
    "print(f\"Model loaded: trained acc: {checkpoint['val_acc']:.4f}; {len(checkpoint['train_classes'])} classes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583526a-88ca-4992-89a8-6e3fc5901aa4",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455c3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T17:06:26.963432Z",
     "iopub.status.busy": "2026-01-08T17:06:26.962682Z",
     "iopub.status.idle": "2026-01-08T17:06:27.393173Z",
     "shell.execute_reply": "2026-01-08T17:06:27.392575Z",
     "shell.execute_reply.started": "2026-01-08T17:06:26.963400Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestDataset\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestConfig\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Me\\Git\\Github\\aio25-mix002\\m07-p7.1\\src\\dataset.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Me\\Git\\Github\\aio25-mix002\\m07-p7.1\\.venv\\Lib\\site-packages\\torch\\__init__.py:2222\u001b[39m\n\u001b[32m   2218\u001b[39m sys.modules.setdefault(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.classes\u001b[39m\u001b[33m\"\u001b[39m, classes)\n\u001b[32m   2220\u001b[39m \u001b[38;5;66;03m# quantization depends on torch.fx and torch.ops\u001b[39;00m\n\u001b[32m   2221\u001b[39m \u001b[38;5;66;03m# Import quantization\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2222\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization \u001b[38;5;28;01mas\u001b[39;00m quantization  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2224\u001b[39m \u001b[38;5;66;03m# Import the quasi random sampler\u001b[39;00m\n\u001b[32m   2225\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quasirandom \u001b[38;5;28;01mas\u001b[39;00m quasirandom  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Me\\Git\\Github\\aio25-mix002\\m07-p7.1\\.venv\\Lib\\site-packages\\torch\\quantization\\__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_quantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuse_modules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fuse_modules\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuser_method_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Me\\Git\\Github\\aio25-mix002\\m07-p7.1\\.venv\\Lib\\site-packages\\torch\\quantization\\fake_quantize.py:10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mis kept here for compatibility while the migration process is ongoing.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[33;03mhere.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_quantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     _is_fake_quant_script_module,\n\u001b[32m     12\u001b[39m     _is_per_channel,\n\u001b[32m     13\u001b[39m     _is_per_tensor,\n\u001b[32m     14\u001b[39m     _is_symmetric_quant,\n\u001b[32m     15\u001b[39m     default_fake_quant,\n\u001b[32m     16\u001b[39m     default_fixed_qparams_range_0to1_fake_quant,\n\u001b[32m     17\u001b[39m     default_fixed_qparams_range_neg1to1_fake_quant,\n\u001b[32m     18\u001b[39m     default_fused_act_fake_quant,\n\u001b[32m     19\u001b[39m     default_fused_per_channel_wt_fake_quant,\n\u001b[32m     20\u001b[39m     default_fused_wt_fake_quant,\n\u001b[32m     21\u001b[39m     default_histogram_fake_quant,\n\u001b[32m     22\u001b[39m     default_per_channel_weight_fake_quant,\n\u001b[32m     23\u001b[39m     default_weight_fake_quant,\n\u001b[32m     24\u001b[39m     disable_fake_quant,\n\u001b[32m     25\u001b[39m     disable_observer,\n\u001b[32m     26\u001b[39m     enable_fake_quant,\n\u001b[32m     27\u001b[39m     enable_observer,\n\u001b[32m     28\u001b[39m     FakeQuantize,\n\u001b[32m     29\u001b[39m     FakeQuantizeBase,\n\u001b[32m     30\u001b[39m     FixedQParamsFakeQuantize,\n\u001b[32m     31\u001b[39m     FusedMovingAvgObsFakeQuantize,\n\u001b[32m     32\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Me\\Git\\Github\\aio25-mix002\\m07-p7.1\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\__init__.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuser_method_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mobserver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_numeric_debugger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     13\u001b[39m     compare_results,\n\u001b[32m     14\u001b[39m     CUSTOM_KEY,\n\u001b[32m     15\u001b[39m     extract_results_from_loggers,\n\u001b[32m     16\u001b[39m     generate_numeric_debug_handle,\n\u001b[32m     17\u001b[39m     NUMERIC_DEBUG_HANDLE_KEY,\n\u001b[32m     18\u001b[39m     prepare_for_propagation_comparison,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     _allow_exported_model_train_eval \u001b[38;5;28;01mas\u001b[39;00m allow_exported_model_train_eval,\n\u001b[32m     22\u001b[39m     _move_exported_model_to_eval \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_eval,\n\u001b[32m     23\u001b[39m     _move_exported_model_to_train \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_train,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Me\\Git\\Github\\aio25-mix002\\m07-p7.1\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\pt2e\\_numeric_debugger.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mns\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_sqnr\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_control_flow_submodules\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphModule, Node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Me\\Git\\Github\\aio25-mix002\\m07-p7.1\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\pt2e\\graph_utils.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Node\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource_matcher_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     check_subgraphs_connected,\n\u001b[32m     10\u001b[39m     get_source_partitions,\n\u001b[32m     11\u001b[39m     SourcePartition,\n\u001b[32m     12\u001b[39m )\n\u001b[32m     15\u001b[39m __all__ = [\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfind_sequential_partitions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mget_control_flow_submodules\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mget_equivalent_types\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mupdate_equivalent_types_dict\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m ]\n\u001b[32m     22\u001b[39m _EQUIVALENT_TYPES: List[Set] = [\n\u001b[32m     23\u001b[39m     {torch.nn.Conv1d, torch.nn.functional.conv1d},\n\u001b[32m     24\u001b[39m     {torch.nn.Conv2d, torch.nn.functional.conv2d},\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     {torch.mul, operator.mul, operator.imul, \u001b[33m\"\u001b[39m\u001b[33mmul\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmul_\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     31\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1022\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1118\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1217\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from src.dataset import TestDataset\n",
    "from src.config import TestConfig\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_cfg = TestConfig()\n",
    "print(\"\\nLoading test dataset...\")\n",
    "test_dataset = TestDataset(\n",
    "    test_cfg.data_root,\n",
    "    num_frames=t_cfg.num_frames,\n",
    "    frame_stride=t_cfg.frame_stride,\n",
    "    image_size=m_cfg.image_size,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=t_cfg.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84ed15-f5b1-4cc2-a914-c92fc23b4f93",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "XW4gvwH8iZIJ",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T17:06:30.960848Z",
     "iopub.status.busy": "2026-01-08T17:06:30.960536Z",
     "iopub.status.idle": "2026-01-08T17:08:29.957866Z",
     "shell.execute_reply": "2026-01-08T17:08:29.957024Z",
     "shell.execute_reply.started": "2026-01-08T17:06:30.960820Z"
    },
    "id": "XW4gvwH8iZIJ",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0205e03f753745dba3867b0c39b5a97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total predictions: 510\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"\\nRunning inference...\")\n",
    "predictions = []\n",
    "checkpoint_classes: list[str] = checkpoint['train_classes']\n",
    "with torch.no_grad():\n",
    "    for videos, video_ids in tqdm(test_loader, desc=\"Inference\"):\n",
    "        videos = videos.to(t_cfg.device)\n",
    "        logits = inf_model(videos)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        for video_id, pred_idx in zip(video_ids.cpu().numpy(), preds.cpu().numpy()):\n",
    "            pred_class = checkpoint_classes[pred_idx]\n",
    "            predictions.append((video_id, pred_class))\n",
    "\n",
    "predictions.sort(key=lambda x: x[0])\n",
    "print(f\"\\nTotal predictions: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee39dc3e-c2f5-41a3-a227-ba5bd7370fbc",
   "metadata": {},
   "source": [
    "## Save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b31bb9e-6c98-4f9c-a357-c2a83bdde836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T17:08:36.782014Z",
     "iopub.status.busy": "2026-01-08T17:08:36.781626Z",
     "iopub.status.idle": "2026-01-08T17:08:36.788754Z",
     "shell.execute_reply": "2026-01-08T17:08:36.788064Z",
     "shell.execute_reply.started": "2026-01-08T17:08:36.781969Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Submission saved to: /kaggle/working/checkpoints/20260108_165037_default_expr/submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission_name = (\n",
    "    f\"submission_vitb{m_cfg.patch_size}\"\n",
    "    f\"_d{m_cfg.depth}h{m_cfg.num_heads}\"\n",
    "    f\"_smif{m_cfg.smif_window}\"\n",
    "    f\"_lr{t_cfg.lr}\"\n",
    "    f\"_bs{t_cfg.batch_size}\"\n",
    "    f\"_f{t_cfg.num_frames}s{t_cfg.frame_stride}\"\n",
    "    f\"_dr{m_cfg.drop_rate}\"\n",
    "    f\"_e{checkpoint['metrics']['epoch']}\"\n",
    "    f\"_acc{checkpoint['val_acc']:.4f}\"\n",
    "    f\".csv\"\n",
    ")\n",
    "submission_path = train_saved_chk_dir / Path(submission_name)\n",
    "with open(submission_path, \"w\") as f:\n",
    "    f.write(\"id,class\\n\")\n",
    "    for video_id, pred_class in predictions:\n",
    "        f.write(f\"{video_id},{pred_class}\\n\")\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(f\"Submission saved to: {submission_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14910023,
     "sourceId": 125907,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "m07-p7.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.587062,
   "end_time": "2026-01-06T03:35:23.698009",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-06T03:35:19.110947",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
