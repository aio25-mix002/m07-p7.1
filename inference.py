import argparse
import os
import torch
import torch.nn as nn  # <--- 1. Cáº¦N THÃŠM IMPORT NÃ€Y
import pandas as pd
from pathlib import Path
from torch.utils.data import DataLoader
from tqdm import tqdm

# Import cÃ¡c module tá»« source code cá»§a báº¡n
from src.dataset import TestDataset, test_collate_fn
from src.model import LSViTForAction
from src.config import ModelConfig

# === DANH SÃCH CHUáº¨N 51 CLASS HMDB51 (A-Z) ===
HMDB51_CLASSES = [
    'brush_hair', 'cartwheel', 'catch', 'chew', 'clap', 
    'climb', 'climb_stairs', 'dive', 'draw_sword', 'dribble', 
    'drink', 'eat', 'fall_floor', 'fencer', 'flic_flac', 
    'golf', 'handstand', 'hit', 'hug', 'jump', 
    'kick', 'kick_ball', 'kiss', 'laugh', 'pick', 
    'pour', 'pullup', 'punch', 'push', 'pushup', 
    'ride_bike', 'ride_horse', 'run', 'shake_hands', 'shoot_ball', 
    'shoot_bow', 'shoot_gun', 'sit', 'situp', 'smile', 
    'smoke', 'somersault', 'stand', 'swing_baseball', 'sword', 
    'sword_exercise', 'talk', 'throw', 'turn', 'walk', 'wave'
]

def save_submission(ids: list, predictions: list, submission_file: Path):
    """LÆ°u file submission Ä‘Ãºng Ä‘á»‹nh dáº¡ng Kaggle yÃªu cáº§u."""
    df = pd.DataFrame({
        'id': ids,
        'class': predictions
    })
    
    try:
        df['id'] = df['id'].astype(int)
        df = df.sort_values(by='id').reset_index(drop=True)
    except ValueError:
        print("Cáº£nh bÃ¡o: ID khÃ´ng pháº£i dáº¡ng sá»‘, sáº½ sort theo string.")
        df = df.sort_values(by='id').reset_index(drop=True)

    is_kaggle_env = os.path.exists('/kaggle/working')
    if is_kaggle_env:
        output_path = Path('/kaggle/working') / submission_file.name
    else:
        output_path = submission_file

    df.to_csv(output_path, index=False)
    print(f"\nâœ… ÄÃ£ táº¡o file submission táº¡i: {output_path}")
    print("5 dÃ²ng Ä‘áº§u tiÃªn cá»§a file:")
    print(df.head())
    return output_path

def parse_args():
    parser = argparse.ArgumentParser(description='Inference on test set')
    parser.add_argument('--checkpoint', type=str, required=True, help='ÄÆ°á»ng dáº«n file best_model.pth')
    parser.add_argument('--data_root', type=str, required=True, help='ThÆ° má»¥c chá»©a folder test')
    parser.add_argument('--submission_file', type=str, default='submission.csv', help='TÃªn file káº¿t quáº£ Ä‘áº§u ra')
    
    parser.add_argument('--num_frames', type=int, default=16)
    parser.add_argument('--image_size', type=int, default=224)
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--num_workers', type=int, default=2)
    
    return parser.parse_args()

def main():
    args = parse_args()
    
    # 1. Thiáº¿t láº­p thiáº¿t bá»‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # 2. Load cáº¥u hÃ¬nh vÃ  Model
    print("Khá»Ÿi táº¡o model...")
    config = ModelConfig()
    config.num_classes = 51
    config.image_size = args.image_size
    
    model = LSViTForAction(config=config).to(device)

    # 3. Load Checkpoint
    # LÆ°u Ã½: Load weights TRÆ¯á»šC khi báº­t DataParallel Ä‘á»ƒ trÃ¡nh lá»—i key mismatch
    print(f"Loading weights tá»«: {args.checkpoint}")
    checkpoint = torch.load(args.checkpoint, map_location=device)
    
    if isinstance(checkpoint, dict) and 'model' in checkpoint:
        state_dict = checkpoint['model']
    else:
        state_dict = checkpoint

    # Clean keys
    new_state_dict = {}
    for k, v in state_dict.items():
        clean_k = k.replace('module.', '').replace('_orig_mod.', '')
        new_state_dict[clean_k] = v
        
    try:
        model.load_state_dict(new_state_dict, strict=True)
    except RuntimeError as e:
        print(f"LÆ°u Ã½: Load strict tháº¥t báº¡i, thá»­ load lá»ng (strict=False)...")
        model.load_state_dict(new_state_dict, strict=False)

    # === 2. THÃŠM ÄOáº N NÃ€Y Äá»‚ KÃCH HOáº T 2 GPU ===
    if torch.cuda.device_count() > 1:
        print(f"ğŸš€ KÃ­ch hoáº¡t cháº¿ Ä‘á»™ Multi-GPU trÃªn {torch.cuda.device_count()} cards!")
        model = nn.DataParallel(model)
    # ===========================================
    
    model.eval()

    # 4. Chuáº©n bá»‹ dá»¯ liá»‡u Test
    print(f"Äá»c dá»¯ liá»‡u tá»«: {args.data_root}")
    test_ds = TestDataset(
        root=args.data_root,
        num_frames=args.num_frames,
        frame_stride=2,
        image_size=args.image_size
    )
    
    test_loader = DataLoader(
        test_ds,
        batch_size=args.batch_size, # LÆ°u Ã½: Khi dÃ¹ng 2 GPU, nÃªn tÄƒng batch_size
        shuffle=False,
        num_workers=args.num_workers,
        collate_fn=test_collate_fn
    )
    print(f"TÃ¬m tháº¥y {len(test_ds)} video clip.")

    # 5. Cháº¡y Inference
    print("Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n...")
    all_preds = []
    all_ids = []
    
    with torch.no_grad():
        for videos, ids in tqdm(test_loader, desc="Processing"):
            videos = videos.to(device)
            
            # Forward pass (DataParallel tá»± chia batch sang cÃ¡c GPU)
            outputs = model(videos)
            
            preds = torch.argmax(outputs, dim=1).cpu().numpy()
            
            all_preds.extend(preds)
            all_ids.extend(ids)

    # 6. Map tá»« sá»‘ sang tÃªn Class
    print("Äang táº¡o file submission...")
    final_class_names = []
    for pred_idx in all_preds:
        if 0 <= pred_idx < len(HMDB51_CLASSES):
            final_class_names.append(HMDB51_CLASSES[pred_idx])
        else:
            final_class_names.append("unknown")

    # 7. LÆ°u file
    save_submission(all_ids, final_class_names, Path(args.submission_file))

if __name__ == '__main__':
    main()